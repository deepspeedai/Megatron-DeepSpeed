Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/token_dropping/build.ninja...
Building extension module token_dropping...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module token_dropping...
Time to load token_dropping op: 0.3406362533569336 seconds
Warning: Permanently added '[192.168.0.137]:40720' (ECDSA) to the list of known hosts.
[2022-10-29 01:37:12,059] [INFO] [runner.py:415:main] Using IP address of 192.168.0.137 for node worker-0
[2022-10-29 01:37:12,060] [INFO] [runner.py:504:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswLCAxLCAyLCAzLCA0LCA1LCA2LCA3XX0= --master_addr=192.168.0.137 --master_port=29500 /home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/examples/random_ltd/../../pretrain_gpt.py --override-lr-scheduler --adam-beta1 0.9 --adam-beta2 0.95 --tensor-model-parallel-size 1 --init-method-std 0.02 --lr-decay-tokens 260000000000 --lr-warmup-tokens 375000000 --micro-batch-size 4 --exit-duration-in-mins 30000000 --global-batch-size 256 --num-layers 12 --hidden-size 768 --num-attention-heads 12 --seq-length 2048 --max-position-embeddings 2048 --train-tokens 300000000000 --train-samples 439453125 --lr 3.0e-4 --min-lr 3.0e-5 --lr-decay-style cosine --split 98,2,0 --log-interval 10 --eval-interval 100 --eval-iters 10 --save-interval 10000 --weight-decay 0.1 --clip-grad 1.0 --hysteresis 2 --num-workers 0 --fp16 --increse-length-token-interval 1.75 --load /blob/users/xiaoxiawu/project/tokendropping/checkpoint/gpt3-0.125B-tokendropping-graduallyIncrease-lr-3.0e-4 --save /blob/users/xiaoxiawu/project/tokendropping/checkpoint/gpt3-0.125B-tokendropping-graduallyIncrease-lr-3.0e-4 --tensorboard-queue-size 1 --log-timers-to-tensorboard --log-batch-size-to-tensorboard --log-validation-ppl-to-tensorboard --tensorboard-dir tensorboard/gpt3-0.125B-tokendropping-graduallyIncrease-lr-3.0e-4_azwus2f200000C6_2022.10.29-01.37.02 --log-optimizer-states-to-tensorboard --vocab-file /blob//data/the_pile_public_merged_nopreprocessing/gpt2-vocab.json --merge-file /blob//data/the_pile_public_merged_nopreprocessing/gpt2-merges.txt --data-path /blob/data/the_pile_public_merged_nopreprocessing/pile_text_document --data-impl mmap --deepspeed --deepspeed_config ds_config_gpt3-0.125B-tokendropping-graduallyIncrease-lr-3.0e-4.json --zero-stage 0 --pipeline-model-parallel-size 1 --no-pipeline-parallel
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/token_dropping/build.ninja...
Building extension module token_dropping...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module token_dropping...
Time to load token_dropping op: 0.2343451976776123 seconds
[2022-10-29 01:37:14,512] [INFO] [launch.py:129:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
[2022-10-29 01:37:14,513] [INFO] [launch.py:129:main] 0 NCCL_VERSION=2.9.8
[2022-10-29 01:37:14,516] [INFO] [launch.py:129:main] 0 NCCL_SOCKET_IFNAME=eth0
[2022-10-29 01:37:14,516] [INFO] [launch.py:129:main] 0 NCCL_NET_GDR_LEVEL=5
[2022-10-29 01:37:14,516] [INFO] [launch.py:129:main] 0 NCCL_DEBUG=INFO
[2022-10-29 01:37:14,516] [INFO] [launch.py:129:main] 0 NCCL_TREE_THRESHOLD=0
[2022-10-29 01:37:14,516] [INFO] [launch.py:129:main] 0 NCCL_ASYNC_ERROR_HANDLING=1
[2022-10-29 01:37:14,516] [INFO] [launch.py:129:main] 0 NCCL_IB_TIMEOUT=20
[2022-10-29 01:37:14,516] [INFO] [launch.py:129:main] 0 NCCL_TOPO_FILE=/opt/msft/topo.xml
[2022-10-29 01:37:14,520] [INFO] [launch.py:136:main] WORLD INFO DICT: {'worker-0': [0, 1, 2, 3, 4, 5, 6, 7]}
[2022-10-29 01:37:14,520] [INFO] [launch.py:142:main] nnodes=1, num_local_procs=8, node_rank=0
[2022-10-29 01:37:14,520] [INFO] [launch.py:155:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0, 1, 2, 3, 4, 5, 6, 7]})
[2022-10-29 01:37:14,520] [INFO] [launch.py:156:main] dist_world_size=8
[2022-10-29 01:37:14,520] [INFO] [launch.py:158:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/token_dropping/build.ninja...
Building extension module token_dropping...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module token_dropping...
Time to load token_dropping op: 0.47367119789123535 seconds
Loading extension module token_dropping...
Time to load token_dropping op: 0.5048916339874268 seconds
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [92m[OKAY][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [92m[OKAY][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
sparse_attn ............ [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
sparse_attn ............ [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
async_io ............... [93m[NO][0m ....... [92m[OKAY][0m
utils .................. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
token_dropping ......... [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/opt/conda/lib/python3.8/site-packages/torch']
async_io torch version...............  ....................[93m[NO][0m  1.11.0+cu113.......
 torch cuda version[92m[OKAY][0m 
............... 11.3
utilstorch hip version  ..................................  [93m[NO][0mNone 
.......nvcc version  [92m[OKAY][0m.....................
 11.3
deepspeed install path ...........quantizer  ['/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed']..............
 deepspeed info[93m[NO][0m  ..........................  0.7.3+7287051a, 7287051a, xiaoxia/token-drop-dynamic-train[92m[OKAY][0m

deepspeed wheel compiled w. ...... torch 1.11, cuda 11.3
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
token_dropping ......... [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/opt/conda/lib/python3.8/site-packages/torch']
torch version .................... 1.11.0+cu113
torch cuda version ............... 11.3
torch hip version ................ None
nvcc version ..................... 11.3
deepspeed install path ........... ['/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed']
deepspeed info ................... 0.7.3+7287051a, 7287051a, xiaoxia/token-drop-dynamic-train
deepspeed wheel compiled w. ...... torch 1.11, cuda 11.3
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/token_dropping/build.ninja...
**** Git info for Megatron: git_hash=7188d07 git_branch=xiaoxia/token-drop-dynamic-train ****
Building extension module token_dropping...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
**** Git info for Megatron: git_hash=7188d07 git_branch=xiaoxia/token-drop-dynamic-train ****
using world size: 8, data-parallel-size: 8, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
using torch.float16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. False
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.95
  adam_eps ........................................ 1e-08
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  bert_binary_head ................................ True
  bert_load ....................................... None
  bf16 ............................................ False
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  checkpoint_activations .......................... False
  checkpoint_in_cpu ............................... False
  checkpoint_num_layers ........................... 1
  clip_grad ....................................... 1.0
  consumed_token_layers ........................... 0
  consumed_train_samples .......................... 0
  consumed_train_tokens ........................... 0
  consumed_valid_samples .......................... 0
  contigious_checkpointing ........................ False
  cpu_optimizer ................................... False
  cpu_torch_adam .................................. False
  create_moe_param_group .......................... False
  curriculum_learning ............................. False
  data_impl ....................................... mmap
  data_parallel_size .............................. 8
  data_path ....................................... ['/blob/data/the_pile_public_merged_nopreprocessing/pile_text_document']
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_seq_length .............................. None
  deepscale ....................................... False
  deepscale_config ................................ None
  deepspeed ....................................... True
  deepspeed_activation_checkpointing .............. False
  deepspeed_config ................................ ds_config_gpt3-0.125B-tokendropping-graduallyIncrease-lr-3.0e-4.json
  deepspeed_mpi ................................... False
  distribute_checkpointed_activations ............. False
  distributed_backend ............................. nccl
  ds_inference .................................... False
  ds_pipeline_enabled ............................. False
  embedding_path .................................. None
  encoder_seq_length .............................. 2048
  eod_mask_loss ................................... False
  eval_interval ................................... 100
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... 30000000
  exit_interval ................................... None
  expert_interval ................................. 2
  ffn_hidden_size ................................. 3072
  finetune ........................................ False
  fp16 ............................................ True
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  global_batch_size ............................... 256
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 768
  hidden_size_teacher ............................. None
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_dim ......................................... 224
  increse_length_token_interval ................... 1.75
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference ....................................... False
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  initial_sequence_length ......................... 128
  kd_alpha_ce ..................................... 1
  kd_beta_ce ...................................... 1
  kd_temp ......................................... 1.0
  kv_channels ..................................... 64
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ /blob/users/xiaoxiawu/project/tokendropping/checkpoint/gpt3-0.125B-tokendropping-graduallyIncrease-lr-3.0e-4
  load_teacher .................................... None
  local_rank ...................................... 0
  log_batch_size_to_tensorboard ................... True
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_num_zeros_in_grad ........................... False
  log_optimizer_states_to_tensorboard ............. True
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... True
  log_validation_ppl_to_tensorboard ............... True
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.0003
  lr_decay_iters .................................. None
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_decay_tokens ................................. 260000000000
  lr_warmup_fraction .............................. None
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  lr_warmup_tokens ................................ 375000000
  make_vocab_size_divisible_by .................... 128
  mask_prob ....................................... 0.15
  masked_softmax_fusion ........................... True
  max_position_embeddings ......................... 2048
  memory_centric_tiled_linear ..................... False
  merge_file ...................................... /blob//data/the_pile_public_merged_nopreprocessing/gpt2-merges.txt
  micro_batch_size ................................ 4
  min_loss_scale .................................. 1.0
  min_lr .......................................... 3e-05
  mlp_type ........................................ standard
  mmap_warmup ..................................... False
  moe_eval_capacity_factor ........................ 1.0
  moe_expert_parallel_size ........................ 1
  moe_loss_coeff .................................. 0.1
  moe_min_capacity ................................ 4
  moe_token_dropping .............................. True
  moe_train_capacity_factor ....................... 1.0
  mos ............................................. False
  no_load_lr_state ................................ False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_pipeline_parallel ............................ True
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 12
  num_attention_heads_teacher ..................... None
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... [1]
  num_experts_teacher ............................. [1]
  num_layers ...................................... 12
  num_layers_per_virtual_pipeline_stage ........... None
  num_layers_teacher .............................. None
  num_workers ..................................... 0
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  override_lr_scheduler ........................... True
  params_dtype .................................... torch.float16
  partition_activations ........................... False
  patch_dim ....................................... 16
  pipeline_model_parallel_size .................... 1
  profile_backward ................................ False
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  remote_device ................................... none
  reset_attention_mask ............................ False
  reset_iteration ................................. False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  sample_rate ..................................... 1.0
  save ............................................ /blob/users/xiaoxiawu/project/tokendropping/checkpoint/gpt3-0.125B-tokendropping-graduallyIncrease-lr-3.0e-4
  save_interval ................................... 10000
  scatter_gather_tensors_in_pipeline .............. True
  scattered_embeddings ............................ False
  seed ............................................ 1234
  seq_length ...................................... 2048
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 98,2,0
  split_transformers .............................. False
  synchronize_each_layer .......................... False
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. tensorboard/gpt3-0.125B-tokendropping-graduallyIncrease-lr-3.0e-4_azwus2f200000C6_2022.10.29-01.37.02
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1
  tile_factor ..................................... 1
  titles_data_path ................................ None
  tokenizer_type .................................. GPT2BPETokenizer
  topk ............................................ 1
  train_iters ..................................... None
  train_samples ................................... 439453125
  train_tokens .................................... 300000000000
  use_checkpoint_lr_scheduler ..................... False
  use_contiguous_buffers_in_ddp ................... False
  use_cpu_initialization .......................... None
  use_one_sent_docs ............................... False
  use_pin_memory .................................. False
  use_tutel ....................................... False
  virtual_pipeline_model_parallel_size ............ None
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /blob//data/the_pile_public_merged_nopreprocessing/gpt2-vocab.json
  weight_decay .................................... 0.1
  world_size ...................................... 8
  zero_allgather_bucket_size ...................... 0.0
  zero_contigious_gradients ....................... False
  zero_reduce_bucket_size ......................... 0.0
  zero_reduce_scatter ............................. False
  zero_stage ...................................... 0
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 8
> building GPT2BPETokenizer tokenizer ...
ninja: no work to do.
Loading extension module token_dropping...
Time to load token_dropping op: 0.4874541759490967 seconds
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
[2022-10-29 01:37:18,061] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [92m[OKAY][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
sparse_attn ............ [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/token_dropping/build.ninja...
async_io ............... [93m[NO][0m ....... [92m[OKAY][0m
utils .................. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
Building extension module token_dropping...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
token_dropping .........Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root... [93m[NO][0m 
....... [92m[OKAY][0m
--------------------------------------------------
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
DeepSpeed general environment info:
torch install path ............... ['/opt/conda/lib/python3.8/site-packages/torch']
torch version .................... 1.11.0+cu113
torch cuda version ............... 11.3
torch hip version ................ None
nvcc version ..................... 11.3
deepspeed install path ........... ['/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed']
deepspeed info ................... 0.7.3+7287051a, 7287051a, xiaoxia/token-drop-dynamic-train
deepspeed wheel compiled w. ...... torch 1.11, cuda 11.3
ninja: no work to do.
Loading extension module token_dropping...
Loading extension module token_dropping...
Time to load token_dropping op: 0.4430091381072998 seconds
Time to load token_dropping op: 0.34856152534484863 seconds
**** Git info for Megatron: git_hash=7188d07 git_branch=xiaoxia/token-drop-dynamic-train ****
Loading extension module token_dropping...
Time to load token_dropping op: 0.29384350776672363 seconds
Loading extension module token_dropping...
Loading extension module token_dropping...
Time to load token_dropping op: 0.27872610092163086 seconds
Time to load token_dropping op: 0.2674238681793213 seconds
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [92m[OKAY][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m--------------------------------------------------

DeepSpeed C++/CUDA extension op reportfused_lamb
 --------------------------------------------------.............
 NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.[93m[NO][0m
 --------------------------------------------------.......
 JIT compiled ops requires ninja[92m[OKAY][0m

ninja .................. [92m[OKAY][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
sparse_attnninja ..................  ............--------------------------------------------------[92m[OKAY][0m 

[93m[NO][0m--------------------------------------------------DeepSpeed C++/CUDA extension op report 

.......op name--------------------------------------------------  
[92m[OKAY][0m................NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
 
installedtransformer--------------------------------------------------  
JIT compiled ops requires ninja
..ninja  ..............................compatible 
 --------------------------------------------------sparse_attn[92m[OKAY][0m[93m[NO][0m
 
 ............--------------------------------------------------....... 
 [93m[NO][0mop namecpu_adam[92m[OKAY][0m  ....... [92m[OKAY][0m
 transformer ............................ 
 installed[93m[NO][0m ............... stochastic_transformer..--------------------------------------------------.......    
[93m[NO][0m.compatible[92m[OKAY][0mDeepSpeed C++/CUDA extension op report  


.......[93m[NO][0m---------------------------------------------------------------------------------------------------- stochastic_transformer ....... [92m[OKAY][0m


cpu_adam NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op................[92m[OKAY][0m
 [93m[NO][0m--------------------------------------------------
  
........JIT compiled ops requires ninja  
[93m[NO][0mcpu_adagrad[92m[OKAY][0m  ninja
...................  cpu_adagrad ..................[92m[OKAY][0m  [93m[NO][0m
 [92m[OKAY][0m...................
--------------------------------------------------
op name  ................[93m[NO][0m   installed[92m[OKAY][0m....... 
..  fused_adam[92m[OKAY][0mcompatible 

.............-------------------------------------------------- fused_adam
[93m[NO][0m  .................... cpu_adam [93m[NO][0m [92m[OKAY][0m ...............
....... fused_lamb ............. [93m[NO][0m  ....... [92m[OKAY][0m[92m[OKAY][0m
[93m[NO][0m
 fused_lamb.......  .............[92m[OKAY][0m 
[93m[NO][0m ....... [92m[OKAY][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
sparse_attnsparse_attn  ............ [93m[NO][0m ................... [92m[OKAY][0m 
[93m[NO][0msparse_attn transformer ....... ............ ............ [92m[OKAY][0m [93m[NO][0m
[93m[NO][0m  .......transformer.......   [92m[OKAY][0m............[92m[OKAY][0m
 
[93m[NO][0mtransformer stochastic_transformer ....... ............ . [92m[OKAY][0m [93m[NO][0m
[93m[NO][0m  stochastic_transformer..............   [92m[OKAY][0m
. [93m[NO][0m [92m[OKAY][0m.......
 [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
async_io ............... [93m[NO][0m ....... [92m[OKAY][0m
utils .................. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
async_io ............... [93m[NO][0m ....... [92m[OKAY][0m
utils .................. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
token_dropping ......... [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
token_dropping ......... [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/opt/conda/lib/python3.8/site-packages/torch']DeepSpeed general environment info:

torch version ....................torch install path  1.11.0+cu113...............
 torch cuda version ............... 11.3['/opt/conda/lib/python3.8/site-packages/torch']

torch hip versiontorch version  ....................................  None1.11.0+cu113

nvcc versiontorch cuda version  ....................................  11.311.3

deepspeed install pathtorch hip version  ...........................  None
['/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed']nvcc version
 deepspeed info.....................  ...................11.3 
0.7.3+7287051a, 7287051a, xiaoxia/token-drop-dynamic-traindeepspeed install path ........... 
['/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed']deepspeed wheel compiled w.
 deepspeed info......  ...................torch 1.11, cuda 11.3 
0.7.3+7287051a, 7287051a, xiaoxia/token-drop-dynamic-train
deepspeed wheel compiled w. ...... torch 1.11, cuda 11.3
async_io ............... [93m[NO][0m ....... [92m[OKAY][0m
utils .................. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
async_io ............... [93m[NO][0m ....... [92m[OKAY][0m
async_ioutils ..................  ...............[93m[NO][0m  [93m[NO][0m.......  .......[92m[OKAY][0m 
[92m[OKAY][0m
quantizer .............. [93m[NO][0m utils.......  ..................[92m[OKAY][0m 
[93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
token_dropping ......... [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
token_dropping ......... [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/opt/conda/lib/python3.8/site-packages/torch']
torch version .................... 1.11.0+cu113
torch cuda version ............... 11.3
torch hip version ................ None
nvcc version ..................... 11.3
deepspeed install path ........... ['/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed']
deepspeed info ................... 0.7.3+7287051a, 7287051a, xiaoxia/token-drop-dynamic-train
deepspeed wheel compiled w. ...... torch 1.11, cuda 11.3
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
token_dropping ......... [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/opt/conda/lib/python3.8/site-packages/torch']
torch version .................... 1.11.0+cu113
torch cuda version ............... 11.3
torch hip version ................ None
nvcc version ..................... 11.3
deepspeed install path ........... ['/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed']
deepspeed info ................... 0.7.3+7287051a, 7287051a, xiaoxia/token-drop-dynamic-train
deepspeed wheel compiled w. ...... torch 1.11, cuda 11.3
DeepSpeed general environment info:
torch install path ............... ['/opt/conda/lib/python3.8/site-packages/torch']
torch version .................... 1.11.0+cu113
torch cuda version ............... 11.3
torch hip version ................ None
nvcc version ..................... 11.3
deepspeed install path ........... ['/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed']
deepspeed info ................... 0.7.3+7287051a, 7287051a, xiaoxia/token-drop-dynamic-train
deepspeed wheel compiled w. ...... torch 1.11, cuda 11.3
**** Git info for Megatron: git_hash=7188d07 git_branch=xiaoxia/token-drop-dynamic-train ****
**** Git info for Megatron: git_hash=7188d07 git_branch=xiaoxia/token-drop-dynamic-train ****
**** Git info for Megatron: git_hash=7188d07 git_branch=xiaoxia/token-drop-dynamic-train ****
**** Git info for Megatron: git_hash=7188d07 git_branch=xiaoxia/token-drop-dynamic-train ****
**** Git info for Megatron: git_hash=7188d07 git_branch=xiaoxia/token-drop-dynamic-train ****
> setting tensorboard ...
2022-10-29 01:37:19.000832: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
> initializing tensor model parallel with size 1
> initializing pipeline model parallel with size 1
> setting random seeds to 1234 ...
> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
> compiling dataset index builder ...
make: Entering directory '/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/data'
>>> done with dataset index builder. Compilation time: 0.129 seconds
> compiling and loading fused kernels ...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/fused_kernels/build/build.ninja...
Building extension module scaled_upper_triang_masked_softmax_cuda...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/3] c++ -MMD -MF scaled_upper_triang_masked_softmax.o.d -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -c /home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/fused_kernels/scaled_upper_triang_masked_softmax.cpp -o scaled_upper_triang_masked_softmax.o 
[2/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -gencode arch=compute_80,code=sm_80 -std=c++14 -c /home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/fused_kernels/scaled_upper_triang_masked_softmax_cuda.cu -o scaled_upper_triang_masked_softmax_cuda.cuda.o 
[3/3] c++ scaled_upper_triang_masked_softmax.o scaled_upper_triang_masked_softmax_cuda.cuda.o -shared -L/opt/conda/lib/python3.8/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda_cu -ltorch_cuda_cpp -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o scaled_upper_triang_masked_softmax_cuda.so
Loading extension module scaled_upper_triang_masked_softmax_cuda...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/fused_kernels/build/build.ninja...
Building extension module scaled_masked_softmax_cuda...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/3] c++ -MMD -MF scaled_masked_softmax.o.d -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -c /home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/fused_kernels/scaled_masked_softmax.cpp -o scaled_masked_softmax.o 
[2/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -gencode arch=compute_80,code=sm_80 -std=c++14 -c /home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/fused_kernels/scaled_masked_softmax_cuda.cu -o scaled_masked_softmax_cuda.cuda.o 
[3/3] c++ scaled_masked_softmax.o scaled_masked_softmax_cuda.cuda.o -shared -L/opt/conda/lib/python3.8/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda_cu -ltorch_cuda_cpp -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o scaled_masked_softmax_cuda.so
Loading extension module scaled_masked_softmax_cuda...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/fused_kernels/build/build.ninja...
Building extension module fused_mix_prec_layer_norm_cuda...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/3] c++ -MMD -MF layer_norm_cuda.o.d -DTORCH_EXTENSION_NAME=fused_mix_prec_layer_norm_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -c /home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/fused_kernels/layer_norm_cuda.cpp -o layer_norm_cuda.o 
[2/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=fused_mix_prec_layer_norm_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 --use_fast_math -maxrregcount=50 -gencode arch=compute_80,code=sm_80 -std=c++14 -c /home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/fused_kernels/layer_norm_cuda_kernel.cu -o layer_norm_cuda_kernel.cuda.o 
[3/3] c++ layer_norm_cuda.o layer_norm_cuda_kernel.cuda.o -shared -L/opt/conda/lib/python3.8/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda_cu -ltorch_cuda_cpp -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o fused_mix_prec_layer_norm_cuda.so
Loading extension module fused_mix_prec_layer_norm_cuda...
azwus2f200000C6:75431:75431 [0] NCCL INFO Bootstrap : Using eth0:192.168.0.137<0>
azwus2f200000C6:75431:75431 [0] NCCL INFO Plugin Path : /opt/nccl-rdma-sharp-plugins.install/lib/libnccl-net.so
azwus2f200000C6:75431:75431 [0] NCCL INFO P2P plugin IBext
azwus2f200000C6:75431:75431 [0] NCCL INFO NCCL_IB_PCI_RELAXED_ORDERING set by environment to 1.
azwus2f200000C6:75431:75431 [0] NCCL INFO NET/IB : Using [0]mlx5_ib0:1/IB/SHARP [1]mlx5_ib1:1/IB/SHARP [2]mlx5_ib2:1/IB/SHARP [3]mlx5_ib3:1/IB/SHARP [4]mlx5_ib4:1/IB/SHARP [5]mlx5_ib5:1/IB/SHARP [6]mlx5_ib6:1/IB/SHARP [7]mlx5_ib7:1/IB/SHARP ; OOB eth0:192.168.0.137<0>
azwus2f200000C6:75431:75431 [0] NCCL INFO Using network IBext
NCCL version 2.10.3+cuda11.3
azwus2f200000C6:75432:75432 [1] NCCL INFO Bootstrap : Using eth0:192.168.0.137<0>
azwus2f200000C6:75443:75443 [7] NCCL INFO Bootstrap : Using eth0:192.168.0.137<0>
azwus2f200000C6:75433:75433 [2] NCCL INFO Bootstrap : Using eth0:192.168.0.137<0>
azwus2f200000C6:75439:75439 [5] NCCL INFO Bootstrap : Using eth0:192.168.0.137<0>
azwus2f200000C6:75441:75441 [6] NCCL INFO Bootstrap : Using eth0:192.168.0.137<0>
azwus2f200000C6:75435:75435 [3] NCCL INFO Bootstrap : Using eth0:192.168.0.137<0>
azwus2f200000C6:75437:75437 [4] NCCL INFO Bootstrap : Using eth0:192.168.0.137<0>
azwus2f200000C6:75443:75443 [7] NCCL INFO Plugin Path : /opt/nccl-rdma-sharp-plugins.install/lib/libnccl-net.so
azwus2f200000C6:75439:75439 [5] NCCL INFO Plugin Path : /opt/nccl-rdma-sharp-plugins.install/lib/libnccl-net.so
azwus2f200000C6:75443:75443 [7] NCCL INFO P2P plugin IBext
azwus2f200000C6:75432:75432 [1] NCCL INFO Plugin Path : /opt/nccl-rdma-sharp-plugins.install/lib/libnccl-net.so
azwus2f200000C6:75439:75439 [5] NCCL INFO P2P plugin IBext
azwus2f200000C6:75443:75443 [7] NCCL INFO NCCL_IB_PCI_RELAXED_ORDERING set by environment to 1.
azwus2f200000C6:75433:75433 [2] NCCL INFO Plugin Path : /opt/nccl-rdma-sharp-plugins.install/lib/libnccl-net.so
azwus2f200000C6:75439:75439 [5] NCCL INFO NCCL_IB_PCI_RELAXED_ORDERING set by environment to 1.
azwus2f200000C6:75432:75432 [1] NCCL INFO P2P plugin IBext
azwus2f200000C6:75441:75441 [6] NCCL INFO Plugin Path : /opt/nccl-rdma-sharp-plugins.install/lib/libnccl-net.so
azwus2f200000C6:75433:75433 [2] NCCL INFO P2P plugin IBext
azwus2f200000C6:75432:75432 [1] NCCL INFO NCCL_IB_PCI_RELAXED_ORDERING set by environment to 1.
azwus2f200000C6:75441:75441 [6] NCCL INFO P2P plugin IBext
azwus2f200000C6:75441:75441 [6] NCCL INFO NCCL_IB_PCI_RELAXED_ORDERING set by environment to 1.
azwus2f200000C6:75433:75433 [2] NCCL INFO NCCL_IB_PCI_RELAXED_ORDERING set by environment to 1.
azwus2f200000C6:75435:75435 [3] NCCL INFO Plugin Path : /opt/nccl-rdma-sharp-plugins.install/lib/libnccl-net.so
azwus2f200000C6:75437:75437 [4] NCCL INFO Plugin Path : /opt/nccl-rdma-sharp-plugins.install/lib/libnccl-net.so
azwus2f200000C6:75435:75435 [3] NCCL INFO P2P plugin IBext
azwus2f200000C6:75437:75437 [4] NCCL INFO P2P plugin IBext
azwus2f200000C6:75435:75435 [3] NCCL INFO NCCL_IB_PCI_RELAXED_ORDERING set by environment to 1.
azwus2f200000C6:75437:75437 [4] NCCL INFO NCCL_IB_PCI_RELAXED_ORDERING set by environment to 1.
azwus2f200000C6:75439:75439 [5] NCCL INFO NET/IB : Using [0]mlx5_ib0:1/IB/SHARP [1]mlx5_ib1:1/IB/SHARP [2]mlx5_ib2:1/IB/SHARP [3]mlx5_ib3:1/IB/SHARP [4]mlx5_ib4:1/IB/SHARP [5]mlx5_ib5:1/IB/SHARP [6]mlx5_ib6:1/IB/SHARP [7]mlx5_ib7:1/IB/SHARP ; OOB eth0:192.168.0.137<0>
azwus2f200000C6:75437:75437 [4] NCCL INFO NET/IB : Using [0]mlx5_ib0:1/IB/SHARP [1]mlx5_ib1:1/IB/SHARP [2]mlx5_ib2:1/IB/SHARP [3]mlx5_ib3:1/IB/SHARP [4]mlx5_ib4:1/IB/SHARP [5]mlx5_ib5:1/IB/SHARP [6]mlx5_ib6:1/IB/SHARP [7]mlx5_ib7:1/IB/SHARP ; OOB eth0:192.168.0.137<0>
azwus2f200000C6:75439:75439 [5] NCCL INFO Using network IBext
azwus2f200000C6:75435:75435 [3] NCCL INFO NET/IB : Using [0]mlx5_ib0:1/IB/SHARP [1]mlx5_ib1:1/IB/SHARP [2]mlx5_ib2:1/IB/SHARP [3]mlx5_ib3:1/IB/SHARP [4]mlx5_ib4:1/IB/SHARP [5]mlx5_ib5:1/IB/SHARP [6]mlx5_ib6:1/IB/SHARP [7]mlx5_ib7:1/IB/SHARP ; OOB eth0:192.168.0.137<0>
azwus2f200000C6:75441:75441 [6] NCCL INFO NET/IB : Using [0]mlx5_ib0:1/IB/SHARP [1]mlx5_ib1:1/IB/SHARP [2]mlx5_ib2:1/IB/SHARP [3]mlx5_ib3:1/IB/SHARP [4]mlx5_ib4:1/IB/SHARP [5]mlx5_ib5:1/IB/SHARP [6]mlx5_ib6:1/IB/SHARP [7]mlx5_ib7:1/IB/SHARP ; OOB eth0:192.168.0.137<0>
azwus2f200000C6:75432:75432 [1] NCCL INFO NET/IB : Using [0]mlx5_ib0:1/IB/SHARP [1]mlx5_ib1:1/IB/SHARP [2]mlx5_ib2:1/IB/SHARP [3]mlx5_ib3:1/IB/SHARP [4]mlx5_ib4:1/IB/SHARP [5]mlx5_ib5:1/IB/SHARP [6]mlx5_ib6:1/IB/SHARP [7]mlx5_ib7:1/IB/SHARP ; OOB eth0:192.168.0.137<0>
azwus2f200000C6:75437:75437 [4] NCCL INFO Using network IBext
azwus2f200000C6:75435:75435 [3] NCCL INFO Using network IBext
azwus2f200000C6:75441:75441 [6] NCCL INFO Using network IBext
azwus2f200000C6:75432:75432 [1] NCCL INFO Using network IBext
azwus2f200000C6:75443:75443 [7] NCCL INFO NET/IB : Using [0]mlx5_ib0:1/IB/SHARP [1]mlx5_ib1:1/IB/SHARP [2]mlx5_ib2:1/IB/SHARP [3]mlx5_ib3:1/IB/SHARP [4]mlx5_ib4:1/IB/SHARP [5]mlx5_ib5:1/IB/SHARP [6]mlx5_ib6:1/IB/SHARP [7]mlx5_ib7:1/IB/SHARP ; OOB eth0:192.168.0.137<0>
azwus2f200000C6:75433:75433 [2] NCCL INFO NET/IB : Using [0]mlx5_ib0:1/IB/SHARP [1]mlx5_ib1:1/IB/SHARP [2]mlx5_ib2:1/IB/SHARP [3]mlx5_ib3:1/IB/SHARP [4]mlx5_ib4:1/IB/SHARP [5]mlx5_ib5:1/IB/SHARP [6]mlx5_ib6:1/IB/SHARP [7]mlx5_ib7:1/IB/SHARP ; OOB eth0:192.168.0.137<0>
azwus2f200000C6:75433:75433 [2] NCCL INFO Using network IBext
azwus2f200000C6:75443:75443 [7] NCCL INFO Using network IBext
azwus2f200000C6:75441:76895 [6] NCCL INFO NCCL_IB_TIMEOUT set by environment to 20.
azwus2f200000C6:75433:76898 [2] NCCL INFO NCCL_IB_TIMEOUT set by environment to 20.
azwus2f200000C6:75437:76891 [4] NCCL INFO NCCL_IB_TIMEOUT set by environment to 20.
azwus2f200000C6:75432:76893 [1] NCCL INFO NCCL_IB_TIMEOUT set by environment to 20.
azwus2f200000C6:75431:76836 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 20.
azwus2f200000C6:75439:76890 [5] NCCL INFO NCCL_IB_TIMEOUT set by environment to 20.
azwus2f200000C6:75435:76894 [3] NCCL INFO NCCL_IB_TIMEOUT set by environment to 20.
azwus2f200000C6:75443:76899 [7] NCCL INFO NCCL_IB_TIMEOUT set by environment to 20.
azwus2f200000C6:75435:76894 [3] NCCL INFO NCCL_NET_GDR_LEVEL set by environment to SYS
azwus2f200000C6:75432:76893 [1] NCCL INFO NCCL_NET_GDR_LEVEL set by environment to SYS
azwus2f200000C6:75433:76898 [2] NCCL INFO NCCL_NET_GDR_LEVEL set by environment to SYS
azwus2f200000C6:75437:76891 [4] NCCL INFO NCCL_NET_GDR_LEVEL set by environment to SYS
azwus2f200000C6:75441:76895 [6] NCCL INFO NCCL_NET_GDR_LEVEL set by environment to SYS
azwus2f200000C6:75439:76890 [5] NCCL INFO NCCL_NET_GDR_LEVEL set by environment to SYS
azwus2f200000C6:75431:76836 [0] NCCL INFO NCCL_NET_GDR_LEVEL set by environment to SYS
azwus2f200000C6:75443:76899 [7] NCCL INFO NCCL_NET_GDR_LEVEL set by environment to SYS
azwus2f200000C6:75443:76899 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->6 [8] -1/-1/-1->7->6 [9] -1/-1/-1->7->6 [10] -1/-1/-1->7->6 [11] -1/-1/-1->7->6 [12] -1/-1/-1->7->6 [13] -1/-1/-1->7->6 [14] -1/-1/-1->7->6 [15] -1/-1/-1->7->6 [16] -1/-1/-1->7->6 [17] -1/-1/-1->7->6 [18] -1/-1/-1->7->6 [19] -1/-1/-1->7->6 [20] -1/-1/-1->7->6 [21] -1/-1/-1->7->6 [22] -1/-1/-1->7->6 [23] -1/-1/-1->7->6
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75443:76899 [7] NCCL INFO Setting affinity for GPU 7 to ffff,0000ffff
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75432:76893 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75433:76898 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:76836 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1
azwus2f200000C6:75433:76898 [2] NCCL INFO Setting affinity for GPU 2 to ffff,0000ffff
azwus2f200000C6:75435:76894 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2 [4] 4/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] 4/-1/-1->3->2 [7] 4/-1/-1->3->2 [8] 4/-1/-1->3->2 [9] 4/-1/-1->3->2 [10] 4/-1/-1->3->2 [11] 4/-1/-1->3->2 [12] 4/-1/-1->3->2 [13] 4/-1/-1->3->2 [14] 4/-1/-1->3->2 [15] 4/-1/-1->3->2 [16] 4/-1/-1->3->2 [17] 4/-1/-1->3->2 [18] 4/-1/-1->3->2 [19] 4/-1/-1->3->2 [20] 4/-1/-1->3->2 [21] 4/-1/-1->3->2 [22] 4/-1/-1->3->2 [23] 4/-1/-1->3->2
azwus2f200000C6:75431:76836 [0] NCCL INFO Setting affinity for GPU 0 to ffff,0000ffff
azwus2f200000C6:75441:76895 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 7/-1/-1->6->5 [9] 7/-1/-1->6->5 [10] 7/-1/-1->6->5 [11] 7/-1/-1->6->5 [12] 7/-1/-1->6->5 [13] 7/-1/-1->6->5 [14] 7/-1/-1->6->5 [15] 7/-1/-1->6->5 [16] 7/-1/-1->6->5 [17] 7/-1/-1->6->5 [18] 7/-1/-1->6->5 [19] 7/-1/-1->6->5 [20] 7/-1/-1->6->5 [21] 7/-1/-1->6->5 [22] 7/-1/-1->6->5 [23] 7/-1/-1->6->5
azwus2f200000C6:75432:76893 [1] NCCL INFO Setting affinity for GPU 1 to ffff,0000ffff
azwus2f200000C6:75439:76890 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] 6/-1/-1->5->4 [7] 6/-1/-1->5->4 [8] 6/-1/-1->5->4 [9] 6/-1/-1->5->4 [10] 6/-1/-1->5->4 [11] 6/-1/-1->5->4 [12] 6/-1/-1->5->4 [13] 6/-1/-1->5->4 [14] 6/-1/-1->5->4 [15] 6/-1/-1->5->4 [16] 6/-1/-1->5->4 [17] 6/-1/-1->5->4 [18] 6/-1/-1->5->4 [19] 6/-1/-1->5->4 [20] 6/-1/-1->5->4 [21] 6/-1/-1->5->4 [22] 6/-1/-1->5->4 [23] 6/-1/-1->5->4
azwus2f200000C6:75435:76894 [3] NCCL INFO Setting affinity for GPU 3 to ffff,0000ffff
azwus2f200000C6:75437:76891 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3 [4] 5/-1/-1->4->3 [5] 5/-1/-1->4->3 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->3 [8] 5/-1/-1->4->3 [9] 5/-1/-1->4->3 [10] 5/-1/-1->4->3 [11] 5/-1/-1->4->3 [12] 5/-1/-1->4->3 [13] 5/-1/-1->4->3 [14] 5/-1/-1->4->3 [15] 5/-1/-1->4->3 [16] 5/-1/-1->4->3 [17] 5/-1/-1->4->3 [18] 5/-1/-1->4->3 [19] 5/-1/-1->4->3 [20] 5/-1/-1->4->3 [21] 5/-1/-1->4->3 [22] 5/-1/-1->4->3 [23] 5/-1/-1->4->3
azwus2f200000C6:75441:76895 [6] NCCL INFO Setting affinity for GPU 6 to ffff,0000ffff
azwus2f200000C6:75437:76891 [4] NCCL INFO Setting affinity for GPU 4 to ffff,0000ffff
azwus2f200000C6:75439:76890 [5] NCCL INFO Setting affinity for GPU 5 to ffff,0000ffff
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 00 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 01 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 02 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 03 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 00 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 04 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 00 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 01 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 05 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 01 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 00 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 00 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 02 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 06 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 02 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 00 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 01 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 01 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 03 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 07 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 03 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 00 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 00 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 01 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 02 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 02 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 04 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 08 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 04 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 01 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 01 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 02 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 03 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 03 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 09 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 05 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 05 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 02 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 02 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 03 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 04 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 04 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 10 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 06 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 06 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 03 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 03 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 04 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 05 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 05 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 07 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 11 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 07 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 04 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 04 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 06 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 05 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 06 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 08 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 12 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 08 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 05 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 05 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 07 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 07 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 09 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 06 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 13 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 09 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 06 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 06 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 08 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 08 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 10 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 14 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 07 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 10 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 07 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 07 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 09 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 09 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 11 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 15 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 11 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 08 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 08 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 08 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 10 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 12 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 10 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 16 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 12 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 09 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 09 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 09 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 11 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 13 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 11 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 17 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 13 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 10 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 10 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 10 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 12 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 14 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 12 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 18 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 14 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 11 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 11 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 11 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 13 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 15 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 13 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 19 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 15 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 12 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 12 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 12 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 16 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 14 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 14 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 20 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 16 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 13 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 13 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 13 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 17 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 15 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 15 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 21 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 17 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 14 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 14 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 14 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 18 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 16 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 16 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 22 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 18 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 15 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 15 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 19 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 15 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 17 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 17 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 23 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 19 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 16 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 16 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 20 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 16 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 18 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 18 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 20 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 17 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 17 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 21 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 17 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 19 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 19 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 21 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 18 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 18 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 22 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 18 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 20 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 20 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 22 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 19 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 19 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Channel 23 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 19 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 21 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 21 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 23 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 20 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 20 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 22 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 20 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 22 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 21 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 21 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 23 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 21 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 23 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 22 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 22 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 22 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 23 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 23 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 23 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Connected all rings
azwus2f200000C6:75432:76893 [1] NCCL INFO Connected all rings
azwus2f200000C6:75439:76890 [5] NCCL INFO Connected all rings
azwus2f200000C6:75441:76895 [6] NCCL INFO Connected all rings
azwus2f200000C6:75435:76894 [3] NCCL INFO Connected all rings
azwus2f200000C6:75437:76891 [4] NCCL INFO Connected all rings
azwus2f200000C6:75443:76899 [7] NCCL INFO Connected all rings
azwus2f200000C6:75433:76898 [2] NCCL INFO Connected all rings
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 00 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 01 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 02 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 03 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 04 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 05 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 06 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 07 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 08 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 09 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 10 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 11 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 12 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 13 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 14 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 15 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 16 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 17 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 18 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 19 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 00 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 20 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 00 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 00 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 00 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 00 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 00 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 01 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 21 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 01 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 01 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 01 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 01 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 01 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 02 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 22 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 02 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 02 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 02 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 02 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 02 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 03 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75443:76899 [7] NCCL INFO Channel 23 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 03 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 03 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 03 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 03 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 03 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 04 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 04 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 04 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 04 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 04 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 05 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 04 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 05 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 05 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 05 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 05 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 06 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 05 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 06 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 06 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 06 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 06 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 07 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 06 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 07 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 07 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 07 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 07 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 08 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 07 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 08 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 08 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 08 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 09 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 08 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 08 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 09 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 09 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 10 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 09 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 09 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 09 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 10 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 10 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 11 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 10 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 10 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 10 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 11 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 11 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 12 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 11 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 11 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 11 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 12 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 12 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 13 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 12 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 12 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 12 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 13 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 13 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 13 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 14 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 13 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 13 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 14 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 14 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 15 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 14 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 14 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 14 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 15 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 15 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 16 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 15 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 15 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 15 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 16 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 16 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 17 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 16 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 16 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 16 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 17 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 17 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 18 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 17 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 17 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 17 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 18 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 18 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 18 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 19 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 18 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 18 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 19 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 19 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 20 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 19 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 19 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 19 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 20 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 20 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 21 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 20 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 20 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 20 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 21 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 21 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 22 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 21 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 21 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 21 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 22 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 22 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:76893 [1] NCCL INFO Channel 23 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 22 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 22 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 22 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:76890 [5] NCCL INFO Channel 23 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:76895 [6] NCCL INFO Channel 23 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75433:76898 [2] NCCL INFO Channel 23 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75435:76894 [3] NCCL INFO Channel 23 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:76891 [4] NCCL INFO Channel 23 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75431:76836 [0] NCCL INFO Connected all trees
azwus2f200000C6:75431:76836 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
azwus2f200000C6:75443:76899 [7] NCCL INFO Connected all trees
azwus2f200000C6:75443:76899 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
azwus2f200000C6:75431:76836 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75443:76899 [7] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75433:76898 [2] NCCL INFO Connected all trees
azwus2f200000C6:75433:76898 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
azwus2f200000C6:75432:76893 [1] NCCL INFO Connected all trees
azwus2f200000C6:75439:76890 [5] NCCL INFO Connected all trees
azwus2f200000C6:75441:76895 [6] NCCL INFO Connected all trees
azwus2f200000C6:75437:76891 [4] NCCL INFO Connected all trees
azwus2f200000C6:75435:76894 [3] NCCL INFO Connected all trees
azwus2f200000C6:75432:76893 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
azwus2f200000C6:75439:76890 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
azwus2f200000C6:75441:76895 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
azwus2f200000C6:75435:76894 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
azwus2f200000C6:75437:76891 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
azwus2f200000C6:75439:76890 [5] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75432:76893 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75441:76895 [6] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75433:76898 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75437:76891 [4] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75435:76894 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75431:76836 [0] NCCL INFO comm 0x7f3570002fb0 rank 0 nranks 8 cudaDev 0 busId 100000 - Init COMPLETE
azwus2f200000C6:75437:76891 [4] NCCL INFO comm 0x7f2658002fb0 rank 4 nranks 8 cudaDev 4 busId b00000 - Init COMPLETE
azwus2f200000C6:75443:76899 [7] NCCL INFO comm 0x7f54fc002fb0 rank 7 nranks 8 cudaDev 7 busId e00000 - Init COMPLETE
azwus2f200000C6:75435:76894 [3] NCCL INFO comm 0x7f86a8002fb0 rank 3 nranks 8 cudaDev 3 busId 400000 - Init COMPLETE
azwus2f200000C6:75439:76890 [5] NCCL INFO comm 0x7fdc34002fb0 rank 5 nranks 8 cudaDev 5 busId c00000 - Init COMPLETE
azwus2f200000C6:75432:76893 [1] NCCL INFO comm 0x7fbc68002fb0 rank 1 nranks 8 cudaDev 1 busId 200000 - Init COMPLETE
azwus2f200000C6:75441:76895 [6] NCCL INFO comm 0x7f8610002fb0 rank 6 nranks 8 cudaDev 6 busId d00000 - Init COMPLETE
azwus2f200000C6:75433:76898 [2] NCCL INFO comm 0x7f4194002fb0 rank 2 nranks 8 cudaDev 2 busId 300000 - Init COMPLETE
azwus2f200000C6:75431:75431 [0] NCCL INFO Launch mode Parallel
>>> done with compiling and loading fused kernels. Compilation time: 200.263 seconds
time to initialize megatron (seconds): 200.967
[after megatron is initialized] datetime: 2022-10-29 01:40:40 
building GPT model ...
[2022-10-29 01:40:41,144] [INFO] [utils.py:827:see_memory_usage] Before Building Model
[2022-10-29 01:40:41,145] [INFO] [utils.py:828:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[2022-10-29 01:40:41,149] [INFO] [utils.py:836:see_memory_usage] CPU Virtual Memory:  used = 58.52 GB, percent = 3.3%
[2022-10-29 01:40:41,248] [INFO] [utils.py:827:see_memory_usage] After Building Model
[2022-10-29 01:40:41,249] [INFO] [utils.py:828:see_memory_usage] MA 0.24 GB         Max_MA 0.24 GB         CA 0.25 GB         Max_CA 0 GB 
[2022-10-29 01:40:41,251] [INFO] [utils.py:836:see_memory_usage] CPU Virtual Memory:  used = 58.53 GB, percent = 3.3%
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 125262336
setting training iterations to 1716613
> learning rate decay style: cosine
DeepSpeed is enabled.
[2022-10-29 01:40:41,261] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.7.3+7287051a, git-hash=7287051a, git-branch=xiaoxia/token-drop-dynamic-train
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75443:77782 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->6 [8] -1/-1/-1->7->6 [9] -1/-1/-1->7->6 [10] -1/-1/-1->7->6 [11] -1/-1/-1->7->6 [12] -1/-1/-1->7->6 [13] -1/-1/-1->7->6 [14] -1/-1/-1->7->6 [15] -1/-1/-1->7->6 [16] -1/-1/-1->7->6 [17] -1/-1/-1->7->6 [18] -1/-1/-1->7->6 [19] -1/-1/-1->7->6 [20] -1/-1/-1->7->6 [21] -1/-1/-1->7->6 [22] -1/-1/-1->7->6 [23] -1/-1/-1->7->6
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75443:77782 [7] NCCL INFO Setting affinity for GPU 7 to ffff,0000ffff
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75433:77783 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75432:77785 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0
azwus2f200000C6:75433:77783 [2] NCCL INFO Setting affinity for GPU 2 to ffff,0000ffff
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75435:77786 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2 [4] 4/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] 4/-1/-1->3->2 [7] 4/-1/-1->3->2 [8] 4/-1/-1->3->2 [9] 4/-1/-1->3->2 [10] 4/-1/-1->3->2 [11] 4/-1/-1->3->2 [12] 4/-1/-1->3->2 [13] 4/-1/-1->3->2 [14] 4/-1/-1->3->2 [15] 4/-1/-1->3->2 [16] 4/-1/-1->3->2 [17] 4/-1/-1->3->2 [18] 4/-1/-1->3->2 [19] 4/-1/-1->3->2 [20] 4/-1/-1->3->2 [21] 4/-1/-1->3->2 [22] 4/-1/-1->3->2 [23] 4/-1/-1->3->2
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75432:77785 [1] NCCL INFO Setting affinity for GPU 1 to ffff,0000ffff
azwus2f200000C6:75437:77784 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3 [4] 5/-1/-1->4->3 [5] 5/-1/-1->4->3 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->3 [8] 5/-1/-1->4->3 [9] 5/-1/-1->4->3 [10] 5/-1/-1->4->3 [11] 5/-1/-1->4->3 [12] 5/-1/-1->4->3 [13] 5/-1/-1->4->3 [14] 5/-1/-1->4->3 [15] 5/-1/-1->4->3 [16] 5/-1/-1->4->3 [17] 5/-1/-1->4->3 [18] 5/-1/-1->4->3 [19] 5/-1/-1->4->3 [20] 5/-1/-1->4->3 [21] 5/-1/-1->4->3 [22] 5/-1/-1->4->3 [23] 5/-1/-1->4->3
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75435:77786 [3] NCCL INFO Setting affinity for GPU 3 to ffff,0000ffff
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75437:77784 [4] NCCL INFO Setting affinity for GPU 4 to ffff,0000ffff
azwus2f200000C6:75439:77781 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] 6/-1/-1->5->4 [7] 6/-1/-1->5->4 [8] 6/-1/-1->5->4 [9] 6/-1/-1->5->4 [10] 6/-1/-1->5->4 [11] 6/-1/-1->5->4 [12] 6/-1/-1->5->4 [13] 6/-1/-1->5->4 [14] 6/-1/-1->5->4 [15] 6/-1/-1->5->4 [16] 6/-1/-1->5->4 [17] 6/-1/-1->5->4 [18] 6/-1/-1->5->4 [19] 6/-1/-1->5->4 [20] 6/-1/-1->5->4 [21] 6/-1/-1->5->4 [22] 6/-1/-1->5->4 [23] 6/-1/-1->5->4
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7
azwus2f200000C6:75441:77787 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 7/-1/-1->6->5 [9] 7/-1/-1->6->5 [10] 7/-1/-1->6->5 [11] 7/-1/-1->6->5 [12] 7/-1/-1->6->5 [13] 7/-1/-1->6->5 [14] 7/-1/-1->6->5 [15] 7/-1/-1->6->5 [16] 7/-1/-1->6->5 [17] 7/-1/-1->6->5 [18] 7/-1/-1->6->5 [19] 7/-1/-1->6->5 [20] 7/-1/-1->6->5 [21] 7/-1/-1->6->5 [22] 7/-1/-1->6->5 [23] 7/-1/-1->6->5
azwus2f200000C6:75439:77781 [5] NCCL INFO Setting affinity for GPU 5 to ffff,0000ffff
azwus2f200000C6:75431:77780 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1
azwus2f200000C6:75431:77780 [0] NCCL INFO Setting affinity for GPU 0 to ffff,0000ffff
azwus2f200000C6:75441:77787 [6] NCCL INFO Setting affinity for GPU 6 to ffff,0000ffff
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 00 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 01 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 02 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 00 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 03 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 00 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 00 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 01 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 04 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 01 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 00 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 00 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 00 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 01 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 02 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 05 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 02 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 01 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 01 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 01 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 00 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 02 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 03 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 06 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 03 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 02 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 02 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 02 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 01 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 03 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 04 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 07 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 03 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 04 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 03 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 02 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 03 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 05 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 04 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 08 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 04 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 05 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 04 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 03 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 04 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 06 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 05 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 09 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 05 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 06 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 05 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 05 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 04 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 07 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 06 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 10 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 06 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 07 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 06 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 05 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 06 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 08 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 07 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 11 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 08 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 09 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 07 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 07 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 08 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 06 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 07 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 10 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 12 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 08 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 09 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 08 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 07 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 08 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 09 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 11 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 10 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 13 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 09 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 09 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 08 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 10 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 09 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 12 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 14 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 11 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 10 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 10 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 09 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 10 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 11 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 13 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 15 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 12 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 11 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 10 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 11 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 11 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 12 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 14 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 16 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 13 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 12 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 12 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 11 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 12 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 13 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 15 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 17 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 14 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 13 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 13 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 12 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 13 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 16 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 14 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 15 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 18 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 14 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 14 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 13 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 17 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 14 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 15 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 16 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 19 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 15 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 15 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 18 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 14 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 15 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 17 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 16 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 20 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 16 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 18 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 17 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 16 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 15 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 21 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 16 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 19 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 17 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 18 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 17 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 19 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 18 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 18 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 19 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 16 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 22 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 17 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 20 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 19 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 20 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 17 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 19 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 20 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 18 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 21 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 23 : 7[e00000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 20 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 21 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 18 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 20 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 21 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 22 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 19 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 21 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 22 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 21 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 19 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 22 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 23 : 2[300000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 20 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 22 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 23 : 3[400000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 22 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 21 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 23 : 5[c00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 20 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Channel 23 : 0[100000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 23 : 6[d00000] -> 7[e00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 22 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 21 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 23 : 1[200000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 22 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 23 : 4[b00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Connected all rings
azwus2f200000C6:75443:77782 [7] NCCL INFO Connected all rings
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 00 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 01 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 02 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 03 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 04 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75431:77780 [0] NCCL INFO Connected all rings
azwus2f200000C6:75433:77783 [2] NCCL INFO Connected all rings
azwus2f200000C6:75432:77785 [1] NCCL INFO Connected all rings
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 05 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Connected all rings
azwus2f200000C6:75437:77784 [4] NCCL INFO Connected all rings
azwus2f200000C6:75439:77781 [5] NCCL INFO Connected all rings
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 06 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 07 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 08 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 09 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 10 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 11 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 12 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 13 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 00 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 14 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 01 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 15 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 02 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 00 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 00 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 16 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 03 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 00 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 00 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 00 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 01 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 01 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 17 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 04 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 01 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 01 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 01 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 02 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 02 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 18 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 05 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 02 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 02 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 02 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 03 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 03 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 19 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 06 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 03 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 03 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 03 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 04 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 04 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 20 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 07 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 04 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 04 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 04 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 05 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 05 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 21 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 08 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 05 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 05 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 05 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 06 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 06 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 22 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 09 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 06 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 06 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 06 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 07 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 07 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Channel 23 : 7[e00000] -> 6[d00000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 10 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 07 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 07 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 07 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 08 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 08 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 11 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 08 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 08 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 08 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 09 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 09 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 12 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 09 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 09 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 09 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 10 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 10 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 10 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 13 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 10 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 10 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 11 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 11 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 11 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 14 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 11 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 11 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 12 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 12 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 12 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 15 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 12 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 12 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 13 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 13 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 13 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 16 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 14 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 13 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 14 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 14 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 13 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 17 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 15 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 14 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 15 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 15 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 14 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 16 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 18 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 15 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 16 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 16 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 15 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 17 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 19 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 16 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 17 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 17 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 16 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 20 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 18 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 17 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 18 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 17 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 18 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 19 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 21 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 18 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 19 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 19 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 18 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 20 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 22 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 19 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 20 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 20 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 19 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 21 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 20 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 21 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75441:77787 [6] NCCL INFO Channel 23 : 6[d00000] -> 5[c00000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 21 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 20 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 22 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 21 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 22 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 22 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 21 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75432:77785 [1] NCCL INFO Channel 23 : 1[200000] -> 0[100000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 22 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75435:77786 [3] NCCL INFO Channel 23 : 3[400000] -> 2[300000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 22 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75433:77783 [2] NCCL INFO Channel 23 : 2[300000] -> 1[200000] via P2P/IPC/read
azwus2f200000C6:75439:77781 [5] NCCL INFO Channel 23 : 5[c00000] -> 4[b00000] via P2P/IPC/read
azwus2f200000C6:75437:77784 [4] NCCL INFO Channel 23 : 4[b00000] -> 3[400000] via P2P/IPC/read
azwus2f200000C6:75443:77782 [7] NCCL INFO Connected all trees
azwus2f200000C6:75443:77782 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
azwus2f200000C6:75431:77780 [0] NCCL INFO Connected all trees
azwus2f200000C6:75431:77780 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
azwus2f200000C6:75443:77782 [7] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75431:77780 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75432:77785 [1] NCCL INFO Connected all trees
azwus2f200000C6:75432:77785 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
azwus2f200000C6:75433:77783 [2] NCCL INFO Connected all trees
azwus2f200000C6:75433:77783 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
azwus2f200000C6:75441:77787 [6] NCCL INFO Connected all trees
azwus2f200000C6:75439:77781 [5] NCCL INFO Connected all trees
azwus2f200000C6:75435:77786 [3] NCCL INFO Connected all trees
azwus2f200000C6:75437:77784 [4] NCCL INFO Connected all trees
azwus2f200000C6:75441:77787 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
azwus2f200000C6:75435:77786 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
azwus2f200000C6:75439:77781 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
azwus2f200000C6:75437:77784 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
azwus2f200000C6:75433:77783 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75435:77786 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75441:77787 [6] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75432:77785 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75437:77784 [4] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75439:77781 [5] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75439:77781 [5] NCCL INFO comm 0x7fd6f0002fb0 rank 5 nranks 8 cudaDev 5 busId c00000 - Init COMPLETE
azwus2f200000C6:75441:77787 [6] NCCL INFO comm 0x7f80b0002fb0 rank 6 nranks 8 cudaDev 6 busId d00000 - Init COMPLETE
azwus2f200000C6:75443:77782 [7] NCCL INFO comm 0x7f4fd8002fb0 rank 7 nranks 8 cudaDev 7 busId e00000 - Init COMPLETE
azwus2f200000C6:75431:77780 [0] NCCL INFO comm 0x7f3010002fb0 rank 0 nranks 8 cudaDev 0 busId 100000 - Init COMPLETE
azwus2f200000C6:75433:77783 [2] NCCL INFO comm 0x7f3c54002fb0 rank 2 nranks 8 cudaDev 2 busId 300000 - Init COMPLETE
azwus2f200000C6:75432:77785 [1] NCCL INFO comm 0x7fb70c002fb0 rank 1 nranks 8 cudaDev 1 busId 200000 - Init COMPLETE
azwus2f200000C6:75437:77784 [4] NCCL INFO comm 0x7f2114002fb0 rank 4 nranks 8 cudaDev 4 busId b00000 - Init COMPLETE
azwus2f200000C6:75435:77786 [3] NCCL INFO comm 0x7f8184002fb0 rank 3 nranks 8 cudaDev 3 busId 400000 - Init COMPLETE
azwus2f200000C6:75431:75431 [0] NCCL INFO Launch mode Parallel
[2022-10-29 01:40:46,463] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2022-10-29 01:40:46,464] [INFO] [logging.py:68:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2022-10-29 01:40:46,467] [INFO] [logging.py:68:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2022-10-29 01:40:46,474] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = {basic_optimizer.__class__.__name__}
[2022-10-29 01:40:46,474] [INFO] [logging.py:68:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...

Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...

Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
[2022-10-29 01:40:46,596] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[2022-10-29 01:40:46,596] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2022-10-29 01:40:46,600] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x7f3783915df0>
[2022-10-29 01:40:46,600] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[2022-10-29 01:40:46,601] [INFO] [config.py:978:print] DeepSpeedEngine configuration:
[2022-10-29 01:40:46,604] [INFO] [config.py:982:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2022-10-29 01:40:46,607] [INFO] [config.py:982:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2022-10-29 01:40:46,607] [INFO] [config.py:982:print]   amp_enabled .................. False
[2022-10-29 01:40:46,607] [INFO] [config.py:982:print]   amp_params ................... False
[2022-10-29 01:40:46,608] [INFO] [config.py:982:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": null, 
    "exps_dir": null, 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2022-10-29 01:40:46,608] [INFO] [config.py:982:print]   bfloat16_enabled ............. False
[2022-10-29 01:40:46,608] [INFO] [config.py:982:print]   checkpoint_tag_validation_enabled  True
[2022-10-29 01:40:46,608] [INFO] [config.py:982:print]   checkpoint_tag_validation_fail  False
[2022-10-29 01:40:46,611] [INFO] [config.py:982:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f37839157f0>
[2022-10-29 01:40:46,611] [INFO] [config.py:982:print]   communication_data_type ...... None
[2022-10-29 01:40:46,611] [INFO] [config.py:982:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2022-10-29 01:40:46,611] [INFO] [config.py:982:print]   curriculum_enabled_legacy .... False
[2022-10-29 01:40:46,611] [INFO] [config.py:982:print]   curriculum_params_legacy ..... {'curriculum_type': 'seqlen', 'min_difficulty': 72, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 221108, 'difficulty_step': 8}}
[2022-10-29 01:40:46,611] [INFO] [config.py:982:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}}
[2022-10-29 01:40:46,611] [INFO] [config.py:982:print]   data_efficiency_enabled ...... False
[2022-10-29 01:40:46,611] [INFO] [config.py:982:print]   dataloader_drop_last ......... False
[2022-10-29 01:40:46,615] [INFO] [config.py:982:print]   disable_allgather ............ False
[2022-10-29 01:40:46,615] [INFO] [config.py:982:print]   dump_state ................... False
[2022-10-29 01:40:46,615] [INFO] [config.py:982:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 500, 'delayed_shift': 2, 'min_scale': 1}
[2022-10-29 01:40:46,615] [INFO] [config.py:982:print]   dynamic_train_config ......... {'random_ltd': {'enabled': False}}
[2022-10-29 01:40:46,615] [INFO] [config.py:982:print]   eigenvalue_enabled ........... False
[2022-10-29 01:40:46,615] [INFO] [config.py:982:print]   eigenvalue_gas_boundary_resolution  1
[2022-10-29 01:40:46,615] [INFO] [config.py:982:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2022-10-29 01:40:46,615] [INFO] [config.py:982:print]   eigenvalue_layer_num ......... 0
[2022-10-29 01:40:46,615] [INFO] [config.py:982:print]   eigenvalue_max_iter .......... 100
[2022-10-29 01:40:46,615] [INFO] [config.py:982:print]   eigenvalue_stability ......... 1e-06
[2022-10-29 01:40:46,615] [INFO] [config.py:982:print]   eigenvalue_tol ............... 0.01
[2022-10-29 01:40:46,615] [INFO] [config.py:982:print]   eigenvalue_verbose ........... False
[2022-10-29 01:40:46,616] [INFO] [config.py:982:print]   elasticity_enabled ........... False
[2022-10-29 01:40:46,616] [INFO] [config.py:982:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2022-10-29 01:40:46,619] [INFO] [config.py:982:print]   fp16_auto_cast ............... False
[2022-10-29 01:40:46,619] [INFO] [config.py:982:print]   fp16_enabled ................. True
[2022-10-29 01:40:46,619] [INFO] [config.py:982:print]   fp16_master_weights_and_gradients  False
[2022-10-29 01:40:46,619] [INFO] [config.py:982:print]   global_rank .................. 0
[2022-10-29 01:40:46,619] [INFO] [config.py:982:print]   gradient_accumulation_steps .. 8
[2022-10-29 01:40:46,619] [INFO] [config.py:982:print]   gradient_clipping ............ 1.0
[2022-10-29 01:40:46,619] [INFO] [config.py:982:print]   gradient_predivide_factor .... 1.0
[2022-10-29 01:40:46,619] [INFO] [config.py:982:print]   initial_dynamic_scale ........ 2048
[2022-10-29 01:40:46,619] [INFO] [config.py:982:print]   load_universal_checkpoint .... False
[2022-10-29 01:40:46,619] [INFO] [config.py:982:print]   loss_scale ................... 0
[2022-10-29 01:40:46,619] [INFO] [config.py:982:print]   memory_breakdown ............. False
[2022-10-29 01:40:46,619] [INFO] [config.py:982:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f37863641c0>
[2022-10-29 01:40:46,619] [INFO] [config.py:982:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2022-10-29 01:40:46,619] [INFO] [config.py:982:print]   optimizer_legacy_fusion ...... False
[2022-10-29 01:40:46,623] [INFO] [config.py:982:print]   optimizer_name ............... None
[2022-10-29 01:40:46,624] [INFO] [config.py:982:print]   optimizer_params ............. None
[2022-10-29 01:40:46,624] [INFO] [config.py:982:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2022-10-29 01:40:46,624] [INFO] [config.py:982:print]   pld_enabled .................. False
[2022-10-29 01:40:46,624] [INFO] [config.py:982:print]   pld_params ................... False
[2022-10-29 01:40:46,624] [INFO] [config.py:982:print]   prescale_gradients ........... True
[2022-10-29 01:40:46,624] [INFO] [config.py:982:print]   scheduler_name ............... None
[2022-10-29 01:40:46,624] [INFO] [config.py:982:print]   scheduler_params ............. None
[2022-10-29 01:40:46,624] [INFO] [config.py:982:print]   sparse_attention ............. None
[2022-10-29 01:40:46,624] [INFO] [config.py:982:print]   sparse_gradients_enabled ..... False
[2022-10-29 01:40:46,624] [INFO] [config.py:982:print]   steps_per_print .............. 10
[2022-10-29 01:40:46,624] [INFO] [config.py:982:print]   train_batch_size ............. 256
[2022-10-29 01:40:46,624] [INFO] [config.py:982:print]   train_micro_batch_size_per_gpu  4
[2022-10-29 01:40:46,624] [INFO] [config.py:982:print]   wall_clock_breakdown ......... False
[2022-10-29 01:40:46,624] [INFO] [config.py:982:print]   world_size ................... 8
[2022-10-29 01:40:46,624] [INFO] [config.py:982:print]   zero_allow_untested_optimizer  False
[2022-10-29 01:40:46,627] [INFO] [config.py:982:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=True offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2022-10-29 01:40:46,628] [INFO] [config.py:982:print]   zero_enabled ................. False
[2022-10-29 01:40:46,628] [INFO] [config.py:982:print]   zero_optimization_stage ...... 0
[2022-10-29 01:40:46,628] [INFO] [config.py:967:print_user_config]   json = {
    "train_batch_size": 256, 
    "train_micro_batch_size_per_gpu": 4, 
    "steps_per_print": 10, 
    "zero_optimization": {
        "stage": 0, 
        "elastic_checkpoint": true
    }, 
    "gradient_clipping": 1.0, 
    "prescale_gradients": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "loss_scale_window": 500, 
        "hysteresis": 2, 
        "min_loss_scale": 1, 
        "initial_scale_power": 11
    }, 
    "bf16": {
        "enabled": false
    }, 
    "curriculum_learning": {
        "enabled": false, 
        "curriculum_type": "seqlen", 
        "min_difficulty": 72, 
        "max_difficulty": 2.048000e+03, 
        "schedule_type": "fixed_linear", 
        "schedule_config": {
            "total_curriculum_step": 2.211080e+05, 
            "difficulty_step": 8
        }
    }, 
    "wall_clock_breakdown": false
}
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.42646026611328125 seconds
Loading extension module utils...Loading extension module utils...

Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.512645959854126 seconds
Loading extension module utils...
Time to load utils op: 0.5094175338745117 seconds
Time to load utils op: 0.5109109878540039 seconds
Loading extension module utils...
Time to load utils op: 0.4072701930999756 seconds
Time to load utils op: 0.5082387924194336 seconds
Time to load utils op: 0.5102894306182861 seconds
Time to load utils op: 0.514549970626831 seconds
[2022-10-29 01:40:47,754] [WARNING] [engine.py:2641:load_checkpoint] Unable to find latest file at /blob/users/xiaoxiawu/project/tokendropping/checkpoint/gpt3-0.125B-tokendropping-graduallyIncrease-lr-3.0e-4/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2022-10-29 01:40:47,791] [WARNING] [engine.py:2641:load_checkpoint] Unable to find latest file at /blob/users/xiaoxiawu/project/tokendropping/checkpoint/gpt3-0.125B-tokendropping-graduallyIncrease-lr-3.0e-4/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2022-10-29 01:40:47,829] [WARNING] [engine.py:2641:load_checkpoint] Unable to find latest file at /blob/users/xiaoxiawu/project/tokendropping/checkpoint/gpt3-0.125B-tokendropping-graduallyIncrease-lr-3.0e-4/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2022-10-29 01:40:47,867] [WARNING] [engine.py:2641:load_checkpoint] Unable to find latest file at /blob/users/xiaoxiawu/project/tokendropping/checkpoint/gpt3-0.125B-tokendropping-graduallyIncrease-lr-3.0e-4/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2022-10-29 01:40:47,905] [WARNING] [engine.py:2641:load_checkpoint] Unable to find latest file at /blob/users/xiaoxiawu/project/tokendropping/checkpoint/gpt3-0.125B-tokendropping-graduallyIncrease-lr-3.0e-4/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
WARNING: could not find the metadata file /blob/users/xiaoxiawu/project/tokendropping/checkpoint/gpt3-0.125B-tokendropping-graduallyIncrease-lr-3.0e-4 
    will not load any checkpoints and will start from random
[2022-10-29 01:40:47,943] [WARNING] [engine.py:2641:load_checkpoint] Unable to find latest file at /blob/users/xiaoxiawu/project/tokendropping/checkpoint/gpt3-0.125B-tokendropping-graduallyIncrease-lr-3.0e-4/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2022-10-29 01:40:47,981] [WARNING] [engine.py:2641:load_checkpoint] Unable to find latest file at /blob/users/xiaoxiawu/project/tokendropping/checkpoint/gpt3-0.125B-tokendropping-graduallyIncrease-lr-3.0e-4/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[2022-10-29 01:40:48,020] [WARNING] [engine.py:2641:load_checkpoint] Unable to find latest file at /blob/users/xiaoxiawu/project/tokendropping/checkpoint/gpt3-0.125B-tokendropping-graduallyIncrease-lr-3.0e-4/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
time (ms) | load-checkpoint: 976.82
[after model, optimizer, and learning rate scheduler are built] datetime: 2022-10-29 01:40:48 
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      439453125
    validation: 43947520
    test:       2560
> building train, validation, and test datasets for GPT ...
 > building dataset index ...
    reading sizes...
    reading pointers...
    reading document index...
    creating numpy buffer of mmap...
    creating memory view of numpy buffer...
 > finished creating indexed dataset in 0.010687 seconds
    number of documents: 210604984
 > dataset split:
    train:
     document indices in [0, 206392884) total of 206392884 documents
    validation:
     document indices in [206392884, 210604984) total of 4212100 documents
    test:
     document indices in [210604984, 210604984) total of 0 documents
NCCL version 2.10.3+cuda11.3
NCCL version 2.10.3+cuda11.3
NCCL version 2.10.3+cuda11.3
NCCL version 2.10.3+cuda11.3
NCCL version 2.10.3+cuda11.3
NCCL version 2.10.3+cuda11.3
NCCL version 2.10.3+cuda11.3
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75432:77838 [1] NCCL INFO Setting affinity for GPU 1 to ffff,0000ffff
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75437:77826 [4] NCCL INFO Setting affinity for GPU 4 to ffff,0000ffff
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75441:77820 [6] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75439:77829 [5] NCCL INFO Setting affinity for GPU 5 to ffff,0000ffff
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75441:77820 [6] NCCL INFO Setting affinity for GPU 6 to ffff,0000ffff
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75435:77818 [3] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75433:77841 [2] NCCL INFO Setting affinity for GPU 2 to ffff,0000ffff
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75435:77818 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75443:77823 [7] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75431:77844 [0] NCCL INFO Setting affinity for GPU 0 to ffff,0000ffff
azwus2f200000C6:75435:77818 [3] NCCL INFO Setting affinity for GPU 3 to ffff,0000ffff
azwus2f200000C6:75443:77823 [7] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75443:77823 [7] NCCL INFO Setting affinity for GPU 7 to ffff,0000ffff
azwus2f200000C6:75431:77844 [0] NCCL INFO Connected all rings
azwus2f200000C6:75431:77844 [0] NCCL INFO Connected all trees
azwus2f200000C6:75431:77844 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75432:77838 [1] NCCL INFO Connected all rings
azwus2f200000C6:75431:77844 [0] NCCL INFO comm 0x7e7fcc002fb0 rank 0 nranks 1 cudaDev 0 busId 100000 - Init COMPLETE
azwus2f200000C6:75432:77838 [1] NCCL INFO Connected all trees
azwus2f200000C6:75433:77841 [2] NCCL INFO Connected all rings
azwus2f200000C6:75432:77838 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75437:77826 [4] NCCL INFO Connected all rings
azwus2f200000C6:75433:77841 [2] NCCL INFO Connected all trees
azwus2f200000C6:75435:77818 [3] NCCL INFO Connected all rings
azwus2f200000C6:75433:77841 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75437:77826 [4] NCCL INFO Connected all trees
azwus2f200000C6:75439:77829 [5] NCCL INFO Connected all rings
azwus2f200000C6:75437:77826 [4] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75435:77818 [3] NCCL INFO Connected all trees
azwus2f200000C6:75441:77820 [6] NCCL INFO Connected all rings
azwus2f200000C6:75439:77829 [5] NCCL INFO Connected all trees
azwus2f200000C6:75435:77818 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75443:77823 [7] NCCL INFO Connected all rings
azwus2f200000C6:75439:77829 [5] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75443:77823 [7] NCCL INFO Connected all trees
azwus2f200000C6:75441:77820 [6] NCCL INFO Connected all trees
azwus2f200000C6:75443:77823 [7] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75441:77820 [6] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
 > loading doc-idx mapping from /blob/data/the_pile_public_merged_nopreprocessing/pile_text_document_train_indexmap_439453125ns_2048sl_1234s_doc_idx.npyazwus2f200000C6:75432:77838 [1] NCCL INFO comm 0x7f069c002fb0 rank 0 nranks 1 cudaDev 1 busId 200000 - Init COMPLETE

azwus2f200000C6:75433:77841 [2] NCCL INFO comm 0x7e8bb4002fb0 rank 0 nranks 1 cudaDev 2 busId 300000 - Init COMPLETE
azwus2f200000C6:75437:77826 [4] NCCL INFO comm 0x7e7098002fb0 rank 0 nranks 1 cudaDev 4 busId b00000 - Init COMPLETE
azwus2f200000C6:75435:77818 [3] NCCL INFO comm 0x7ed100002fb0 rank 0 nranks 1 cudaDev 3 busId 400000 - Init COMPLETE
azwus2f200000C6:75443:77823 [7] NCCL INFO comm 0x7e9f74002fb0 rank 0 nranks 1 cudaDev 7 busId e00000 - Init COMPLETE
azwus2f200000C6:75439:77829 [5] NCCL INFO comm 0x7f2678002fb0 rank 0 nranks 1 cudaDev 5 busId c00000 - Init COMPLETE
azwus2f200000C6:75441:77820 [6] NCCL INFO comm 0x7ed044002fb0 rank 0 nranks 1 cudaDev 6 busId d00000 - Init COMPLETE
 > loading sample-idx mapping from /blob/data/the_pile_public_merged_nopreprocessing/pile_text_document_train_indexmap_439453125ns_2048sl_1234s_sample_idx.npy
 > loading shuffle-idx mapping from /blob/data/the_pile_public_merged_nopreprocessing/pile_text_document_train_indexmap_439453125ns_2048sl_1234s_shuffle_idx.npy
    loaded indexed file in 0.013 seconds
    total number of samples: 537390992
    total number of epochs: 3
 > loading doc-idx mapping from /blob/data/the_pile_public_merged_nopreprocessing/pile_text_document_valid_indexmap_43947520ns_2048sl_1234s_doc_idx.npy
 > loading sample-idx mapping from /blob/data/the_pile_public_merged_nopreprocessing/pile_text_document_valid_indexmap_43947520ns_2048sl_1234s_sample_idx.npy
 > loading shuffle-idx mapping from /blob/data/the_pile_public_merged_nopreprocessing/pile_text_document_valid_indexmap_43947520ns_2048sl_1234s_shuffle_idx.npy
    loaded indexed file in 0.059 seconds
    total number of samples: 47470692
    total number of epochs: 13
> finished creating GPT datasets ...
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75439:77864 [5] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75439:77864 [5] NCCL INFO Setting affinity for GPU 5 to ffff,0000ffff
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75437:77863 [4] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75437:77863 [4] NCCL INFO Setting affinity for GPU 4 to ffff,0000ffff
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75431:77877 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75431:77877 [0] NCCL INFO Setting affinity for GPU 0 to ffff,0000ffff
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75443:77867 [7] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75443:77867 [7] NCCL INFO Setting affinity for GPU 7 to ffff,0000ffff
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75441:77862 [6] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75441:77862 [6] NCCL INFO Setting affinity for GPU 6 to ffff,0000ffff
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75432:77860 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75432:77860 [1] NCCL INFO Setting affinity for GPU 1 to ffff,0000ffff
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75433:77857 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75433:77857 [2] NCCL INFO Setting affinity for GPU 2 to ffff,0000ffff
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75435:77868 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75435:77868 [3] NCCL INFO Setting affinity for GPU 3 to ffff,0000ffff
azwus2f200000C6:75439:77864 [5] NCCL INFO Connected all rings
azwus2f200000C6:75439:77864 [5] NCCL INFO Connected all trees
azwus2f200000C6:75439:77864 [5] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75437:77863 [4] NCCL INFO Connected all rings
azwus2f200000C6:75437:77863 [4] NCCL INFO Connected all trees
azwus2f200000C6:75437:77863 [4] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75439:77864 [5] NCCL INFO comm 0x7f2448002fb0 rank 0 nranks 1 cudaDev 5 busId c00000 - Init COMPLETE
azwus2f200000C6:75437:77863 [4] NCCL INFO comm 0x7e6e68002fb0 rank 0 nranks 1 cudaDev 4 busId b00000 - Init COMPLETE
azwus2f200000C6:75431:77877 [0] NCCL INFO Connected all rings
azwus2f200000C6:75431:77877 [0] NCCL INFO Connected all trees
azwus2f200000C6:75431:77877 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75443:77867 [7] NCCL INFO Connected all rings
azwus2f200000C6:75441:77862 [6] NCCL INFO Connected all rings
azwus2f200000C6:75441:77862 [6] NCCL INFO Connected all trees
azwus2f200000C6:75443:77867 [7] NCCL INFO Connected all trees
azwus2f200000C6:75441:77862 [6] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75443:77867 [7] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75431:77877 [0] NCCL INFO comm 0x7e7d9c002fb0 rank 0 nranks 1 cudaDev 0 busId 100000 - Init COMPLETE
azwus2f200000C6:75441:77862 [6] NCCL INFO comm 0x7ece14002fb0 rank 0 nranks 1 cudaDev 6 busId d00000 - Init COMPLETE
azwus2f200000C6:75443:77867 [7] NCCL INFO comm 0x7e9d44002fb0 rank 0 nranks 1 cudaDev 7 busId e00000 - Init COMPLETE
azwus2f200000C6:75432:77860 [1] NCCL INFO Connected all rings
azwus2f200000C6:75433:77857 [2] NCCL INFO Connected all rings
azwus2f200000C6:75432:77860 [1] NCCL INFO Connected all trees
azwus2f200000C6:75432:77860 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75433:77857 [2] NCCL INFO Connected all trees
azwus2f200000C6:75433:77857 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75432:77860 [1] NCCL INFO comm 0x7f046c002fb0 rank 0 nranks 1 cudaDev 1 busId 200000 - Init COMPLETE
azwus2f200000C6:75433:77857 [2] NCCL INFO comm 0x7e8984002fb0 rank 0 nranks 1 cudaDev 2 busId 300000 - Init COMPLETE
azwus2f200000C6:75435:77868 [3] NCCL INFO Connected all rings
azwus2f200000C6:75435:77868 [3] NCCL INFO Connected all trees
azwus2f200000C6:75435:77868 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75435:77868 [3] NCCL INFO comm 0x7eced0002fb0 rank 0 nranks 1 cudaDev 3 busId 400000 - Init COMPLETE
[after dataloaders are built] datetime: 2022-10-29 01:40:55 
time (ms) | model-and-optimizer-setup: 7054.77 | train/valid/test-data-iterators-setup: 7516.83done with setup ...

training ...
[before the start of training step] datetime: 2022-10-29 01:40:55 
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75433:77962 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75433:77962 [2] NCCL INFO Setting affinity for GPU 2 to ffff,0000ffff
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75443:77970 [7] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75443:77970 [7] NCCL INFO Setting affinity for GPU 7 to ffff,0000ffff
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75437:77967 [4] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75437:77967 [4] NCCL INFO Setting affinity for GPU 4 to ffff,0000ffff
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75441:77968 [6] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75441:77968 [6] NCCL INFO Setting affinity for GPU 6 to ffff,0000ffff
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75435:77971 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75435:77971 [3] NCCL INFO Setting affinity for GPU 3 to ffff,0000ffff
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75431:77966 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75431:77966 [0] NCCL INFO Setting affinity for GPU 0 to ffff,0000ffff
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75439:77963 [5] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75439:77963 [5] NCCL INFO Setting affinity for GPU 5 to ffff,0000ffff
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 00/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 01/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 02/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 03/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 04/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 05/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 06/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 07/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 08/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 09/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 10/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 11/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 12/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 13/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 14/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 15/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 16/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 17/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 18/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 19/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 20/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 21/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 22/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 23/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 24/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 25/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 26/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 27/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 28/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 29/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 30/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Channel 31/32 :    0
azwus2f200000C6:75432:77965 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
azwus2f200000C6:75432:77965 [1] NCCL INFO Setting affinity for GPU 1 to ffff,0000ffff
azwus2f200000C6:75433:77962 [2] NCCL INFO Connected all rings
azwus2f200000C6:75433:77962 [2] NCCL INFO Connected all trees
azwus2f200000C6:75433:77962 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75443:77970 [7] NCCL INFO Connected all rings
azwus2f200000C6:75443:77970 [7] NCCL INFO Connected all trees
azwus2f200000C6:75443:77970 [7] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75433:77962 [2] NCCL INFO comm 0x7e8814002fb0 rank 0 nranks 1 cudaDev 2 busId 300000 - Init COMPLETE
azwus2f200000C6:75437:77967 [4] NCCL INFO Connected all rings
azwus2f200000C6:75443:77970 [7] NCCL INFO comm 0x7e9bd4002fb0 rank 0 nranks 1 cudaDev 7 busId e00000 - Init COMPLETE
azwus2f200000C6:75437:77967 [4] NCCL INFO Connected all trees
azwus2f200000C6:75437:77967 [4] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75437:77967 [4] NCCL INFO comm 0x7e6cf8002fb0 rank 0 nranks 1 cudaDev 4 busId b00000 - Init COMPLETE
azwus2f200000C6:75441:77968 [6] NCCL INFO Connected all rings
azwus2f200000C6:75441:77968 [6] NCCL INFO Connected all trees
azwus2f200000C6:75441:77968 [6] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75435:77971 [3] NCCL INFO Connected all rings
azwus2f200000C6:75441:77968 [6] NCCL INFO comm 0x7ecca4002fb0 rank 0 nranks 1 cudaDev 6 busId d00000 - Init COMPLETE
azwus2f200000C6:75435:77971 [3] NCCL INFO Connected all trees
azwus2f200000C6:75431:77966 [0] NCCL INFO Connected all rings
azwus2f200000C6:75435:77971 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75431:77966 [0] NCCL INFO Connected all trees
azwus2f200000C6:75431:77966 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75431:77966 [0] NCCL INFO comm 0x7e7c2c002fb0 rank 0 nranks 1 cudaDev 0 busId 100000 - Init COMPLETE
azwus2f200000C6:75439:77963 [5] NCCL INFO Connected all rings
azwus2f200000C6:75435:77971 [3] NCCL INFO comm 0x7ecd68002fb0 rank 0 nranks 1 cudaDev 3 busId 400000 - Init COMPLETE
azwus2f200000C6:75439:77963 [5] NCCL INFO Connected all trees
azwus2f200000C6:75439:77963 [5] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75432:77965 [1] NCCL INFO Connected all rings
azwus2f200000C6:75432:77965 [1] NCCL INFO Connected all trees
azwus2f200000C6:75432:77965 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
azwus2f200000C6:75432:77965 [1] NCCL INFO comm 0x7f02fc002fb0 rank 0 nranks 1 cudaDev 1 busId 200000 - Init COMPLETE
azwus2f200000C6:75439:77963 [5] NCCL INFO comm 0x7f22d8002fb0 rank 0 nranks 1 cudaDev 5 busId c00000 - Init COMPLETE
[2022-10-29 01:41:04,750] [INFO] [logging.py:68:log_dist] [Rank 0] step=10, skipped=0, lr=[5.308416e-07, 5.308416e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[2022-10-29 01:41:04,753] [INFO] [timer.py:198:stop] 0/10, RunningAvgSamplesPerSec=366.4491528518408, CurrSamplesPerSec=368.84858045030956, MemAllocated=1.64GB, MaxMemAllocated=5.53GB
[Rank 0] (after 10 iterations) memory (MB) | allocated: 1674.31005859375 | max allocated: 5663.76025390625 | reserved: 6098.0 | max reserved: 6098.0
 iteration       10/ 1716613 | consumed samples:         2560 | consumed tokens:      5242880 | elapsed time per iteration (ms): 918.1 | learning rate: 5.308E-07 | global batch size:   256 | lm loss: 1.069112E+01 | loss scale: 2048.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 335.57 | backward-compute: 269.28 | backward-embedding-all-reduce: 0.01 | optimizer: 294.33 | batch-generator: 12.55
[2022-10-29 01:41:10,511] [INFO] [logging.py:68:log_dist] [Rank 0] step=20, skipped=0, lr=[1.1206655999999999e-06, 1.1206655999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[2022-10-29 01:41:10,514] [INFO] [timer.py:198:stop] 0/20, RunningAvgSamplesPerSec=366.8127089676412, CurrSamplesPerSec=368.34447460213346, MemAllocated=1.64GB, MaxMemAllocated=5.53GB
 iteration       20/ 1716613 | consumed samples:         5120 | consumed tokens:     10485760 | elapsed time per iteration (ms): 576.1 | learning rate: 1.121E-06 | global batch size:   256 | lm loss: 1.062067E+01 | loss scale: 2048.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 292.51 | backward-compute: 250.34 | backward-embedding-all-reduce: 0.01 | optimizer: 14.36 | batch-generator: 12.23
[2022-10-29 01:41:16,287] [INFO] [logging.py:68:log_dist] [Rank 0] step=30, skipped=0, lr=[1.7104895999999997e-06, 1.7104895999999997e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[2022-10-29 01:41:16,290] [INFO] [timer.py:198:stop] 0/30, RunningAvgSamplesPerSec=364.724812481615, CurrSamplesPerSec=360.81004328073334, MemAllocated=1.64GB, MaxMemAllocated=5.53GB
 iteration       30/ 1716613 | consumed samples:         7680 | consumed tokens:     15728640 | elapsed time per iteration (ms): 577.7 | learning rate: 1.710E-06 | global batch size:   256 | lm loss: 1.048827E+01 | loss scale: 2048.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 292.47 | backward-compute: 252.51 | backward-embedding-all-reduce: 0.01 | optimizer: 14.27 | batch-generator: 11.41
[2022-10-29 01:41:22,109] [INFO] [logging.py:68:log_dist] [Rank 0] step=40, skipped=0, lr=[2.3003135999999996e-06, 2.3003135999999996e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[2022-10-29 01:41:22,112] [INFO] [timer.py:198:stop] 0/40, RunningAvgSamplesPerSec=363.207648201421, CurrSamplesPerSec=362.49295230687375, MemAllocated=1.64GB, MaxMemAllocated=5.53GB
 iteration       40/ 1716613 | consumed samples:        10240 | consumed tokens:     20971520 | elapsed time per iteration (ms): 582.1 | learning rate: 2.300E-06 | global batch size:   256 | lm loss: 1.025916E+01 | loss scale: 2048.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 297.53 | backward-compute: 251.79 | backward-embedding-all-reduce: 0.01 | optimizer: 14.20 | batch-generator: 11.78
[2022-10-29 01:41:27,893] [INFO] [logging.py:68:log_dist] [Rank 0] step=50, skipped=0, lr=[2.8901375999999997e-06, 2.8901375999999997e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[2022-10-29 01:41:27,896] [INFO] [timer.py:198:stop] 0/50, RunningAvgSamplesPerSec=362.4446606783283, CurrSamplesPerSec=355.2378164494144, MemAllocated=1.64GB, MaxMemAllocated=5.53GB
 iteration       50/ 1716613 | consumed samples:        12800 | consumed tokens:     26214400 | elapsed time per iteration (ms): 578.5 | learning rate: 2.890E-06 | global batch size:   256 | lm loss: 1.009499E+01 | loss scale: 2048.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 293.51 | backward-compute: 252.18 | backward-embedding-all-reduce: 0.01 | optimizer: 14.18 | batch-generator: 12.04
[2022-10-29 01:41:33,670] [INFO] [logging.py:68:log_dist] [Rank 0] step=60, skipped=0, lr=[3.4799615999999993e-06, 3.4799615999999993e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[2022-10-29 01:41:33,673] [INFO] [timer.py:198:stop] 0/60, RunningAvgSamplesPerSec=362.5147282541779, CurrSamplesPerSec=361.0245286723745, MemAllocated=1.64GB, MaxMemAllocated=5.53GB
 iteration       60/ 1716613 | consumed samples:        15360 | consumed tokens:     31457280 | elapsed time per iteration (ms): 577.7 | learning rate: 3.480E-06 | global batch size:   256 | lm loss: 9.833212E+00 | loss scale: 2048.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 294.04 | backward-compute: 251.00 | backward-embedding-all-reduce: 0.01 | optimizer: 14.26 | batch-generator: 12.23
[2022-10-29 01:41:39,477] [INFO] [logging.py:68:log_dist] [Rank 0] step=70, skipped=0, lr=[4.0697856e-06, 4.0697856e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[2022-10-29 01:41:39,480] [INFO] [timer.py:198:stop] 0/70, RunningAvgSamplesPerSec=361.9073261168154, CurrSamplesPerSec=349.5262435579259, MemAllocated=1.64GB, MaxMemAllocated=5.53GB
 iteration       70/ 1716613 | consumed samples:        17920 | consumed tokens:     36700160 | elapsed time per iteration (ms): 580.8 | learning rate: 4.070E-06 | global batch size:   256 | lm loss: 9.580376E+00 | loss scale: 2048.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 293.33 | backward-compute: 254.65 | backward-embedding-all-reduce: 0.01 | optimizer: 14.23 | batch-generator: 11.98
[2022-10-29 01:41:45,237] [INFO] [logging.py:68:log_dist] [Rank 0] step=80, skipped=0, lr=[4.6596095999999995e-06, 4.6596095999999995e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[2022-10-29 01:41:45,240] [INFO] [timer.py:198:stop] 0/80, RunningAvgSamplesPerSec=362.05679947003847, CurrSamplesPerSec=356.9772330737478, MemAllocated=1.64GB, MaxMemAllocated=5.53GB
 iteration       80/ 1716613 | consumed samples:        20480 | consumed tokens:     41943040 | elapsed time per iteration (ms): 575.9 | learning rate: 4.660E-06 | global batch size:   256 | lm loss: 9.481866E+00 | loss scale: 2048.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 292.43 | backward-compute: 250.57 | backward-embedding-all-reduce: 0.01 | optimizer: 14.26 | batch-generator: 12.25
[2022-10-29 01:41:50,997] [INFO] [logging.py:68:log_dist] [Rank 0] step=90, skipped=0, lr=[5.2494336e-06, 5.2494336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[2022-10-29 01:41:50,999] [INFO] [timer.py:198:stop] 0/90, RunningAvgSamplesPerSec=362.14810010041344, CurrSamplesPerSec=363.2385339225933, MemAllocated=1.64GB, MaxMemAllocated=5.53GB
 iteration       90/ 1716613 | consumed samples:        23040 | consumed tokens:     47185920 | elapsed time per iteration (ms): 575.9 | learning rate: 5.249E-06 | global batch size:   256 | lm loss: 9.284685E+00 | loss scale: 2048.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 293.35 | backward-compute: 250.11 | backward-embedding-all-reduce: 0.01 | optimizer: 14.19 | batch-generator: 12.20
[2022-10-29 01:41:56,839] [INFO] [logging.py:68:log_dist] [Rank 0] step=100, skipped=0, lr=[5.8392576e-06, 5.8392576e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[2022-10-29 01:41:56,841] [INFO] [timer.py:198:stop] 0/100, RunningAvgSamplesPerSec=361.98499698321467, CurrSamplesPerSec=362.33539943416196, MemAllocated=1.64GB, MaxMemAllocated=5.53GB
 iteration      100/ 1716613 | consumed samples:        25600 | consumed tokens:     52428800 | elapsed time per iteration (ms): 584.2 | learning rate: 5.839E-06 | global batch size:   256 | lm loss: 9.235689E+00 | loss scale: 2048.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 298.42 | backward-compute: 252.43 | backward-embedding-all-reduce: 0.01 | optimizer: 14.45 | batch-generator: 12.61
-----------------------------------------------------------------------------------------------
 validation loss at iteration 100 | lm loss value: 9.082474E+00 | lm loss PPL: 8.799707E+03 | 
-----------------------------------------------------------------------------------------------
[2022-10-29 01:42:05,806] [INFO] [logging.py:68:log_dist] [Rank 0] step=110, skipped=0, lr=[6.429081599999999e-06, 6.429081599999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[2022-10-29 01:42:05,809] [INFO] [timer.py:198:stop] 0/110, RunningAvgSamplesPerSec=361.70672662043285, CurrSamplesPerSec=361.77480202049605, MemAllocated=1.64GB, MaxMemAllocated=5.53GB
 iteration      110/ 1716613 | consumed samples:        28160 | consumed tokens:     57671680 | elapsed time per iteration (ms): 896.8 | learning rate: 6.429E-06 | global batch size:   256 | lm loss: 9.088985E+00 | loss scale: 2048.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 612.06 | backward-compute: 251.36 | backward-embedding-all-reduce: 0.01 | optimizer: 14.20 | batch-generator: 19.84
[2022-10-29 01:42:11,610] [INFO] [logging.py:68:log_dist] [Rank 0] step=120, skipped=0, lr=[7.018905599999999e-06, 7.018905599999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[2022-10-29 01:42:11,613] [INFO] [timer.py:198:stop] 0/120, RunningAvgSamplesPerSec=361.7307938749869, CurrSamplesPerSec=360.52026248425284, MemAllocated=1.64GB, MaxMemAllocated=5.53GB
 iteration      120/ 1716613 | consumed samples:        30720 | consumed tokens:     62914560 | elapsed time per iteration (ms): 580.3 | learning rate: 7.019E-06 | global batch size:   256 | lm loss: 8.958018E+00 | loss scale: 2048.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 297.16 | backward-compute: 250.45 | backward-embedding-all-reduce: 0.01 | optimizer: 14.22 | batch-generator: 12.53
[2022-10-29 01:42:17,435] [INFO] [logging.py:68:log_dist] [Rank 0] step=130, skipped=0, lr=[7.6087295999999995e-06, 7.6087295999999995e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[2022-10-29 01:42:17,438] [INFO] [timer.py:198:stop] 0/130, RunningAvgSamplesPerSec=361.5810054958206, CurrSamplesPerSec=356.268456090802, MemAllocated=1.64GB, MaxMemAllocated=5.53GB
 iteration      130/ 1716613 | consumed samples:        33280 | consumed tokens:     68157440 | elapsed time per iteration (ms): 582.5 | learning rate: 7.609E-06 | global batch size:   256 | lm loss: 8.870765E+00 | loss scale: 2048.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 298.83 | backward-compute: 250.74 | backward-embedding-all-reduce: 0.01 | optimizer: 14.22 | batch-generator: 12.51
[2022-10-29 01:42:23,258] [INFO] [logging.py:68:log_dist] [Rank 0] step=140, skipped=0, lr=[8.198553599999999e-06, 8.198553599999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[2022-10-29 01:42:23,260] [INFO] [timer.py:198:stop] 0/140, RunningAvgSamplesPerSec=361.1538085320647, CurrSamplesPerSec=356.0699736298953, MemAllocated=1.64GB, MaxMemAllocated=5.53GB
 iteration      140/ 1716613 | consumed samples:        35840 | consumed tokens:     73400320 | elapsed time per iteration (ms): 582.3 | learning rate: 8.199E-06 | global batch size:   256 | lm loss: 8.761093E+00 | loss scale: 2048.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 296.49 | backward-compute: 252.92 | backward-embedding-all-reduce: 0.01 | optimizer: 14.31 | batch-generator: 12.59
[2022-10-29 01:42:29,027] [INFO] [logging.py:68:log_dist] [Rank 0] step=150, skipped=0, lr=[8.788377599999999e-06, 8.788377599999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[2022-10-29 01:42:29,030] [INFO] [timer.py:198:stop] 0/150, RunningAvgSamplesPerSec=361.0607254257902, CurrSamplesPerSec=363.87272101263625, MemAllocated=1.64GB, MaxMemAllocated=5.53GB
 iteration      150/ 1716613 | consumed samples:        38400 | consumed tokens:     78643200 | elapsed time per iteration (ms): 576.9 | learning rate: 8.788E-06 | global batch size:   256 | lm loss: 8.664761E+00 | loss scale: 2048.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 291.16 | backward-compute: 253.34 | backward-embedding-all-reduce: 0.01 | optimizer: 14.27 | batch-generator: 12.56
[2022-10-29 01:42:34,796] [INFO] [logging.py:68:log_dist] [Rank 0] step=160, skipped=0, lr=[9.378201599999998e-06, 9.378201599999998e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[2022-10-29 01:42:34,799] [INFO] [timer.py:198:stop] 0/160, RunningAvgSamplesPerSec=361.04433895105956, CurrSamplesPerSec=353.7426084939724, MemAllocated=1.64GB, MaxMemAllocated=5.53GB
 iteration      160/ 1716613 | consumed samples:        40960 | consumed tokens:     83886080 | elapsed time per iteration (ms): 576.9 | learning rate: 9.378E-06 | global batch size:   256 | lm loss: 8.663841E+00 | loss scale: 2048.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 291.74 | backward-compute: 252.42 | backward-embedding-all-reduce: 0.01 | optimizer: 14.28 | batch-generator: 12.57
[2022-10-29 01:42:37,583] [INFO] [launch.py:286:sigkill_handler] Killing subprocess 75431
Traceback (most recent call last):
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/examples/random_ltd/../../pretrain_gpt.py", line 276, in <module>
    pretrain(train_valid_test_datasets_provider, model_provider, forward_step,Traceback (most recent call last):

  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 166, in pretrain
Traceback (most recent call last):
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/examples/random_ltd/../../pretrain_gpt.py", line 276, in <module>
Traceback (most recent call last):
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/examples/random_ltd/../../pretrain_gpt.py", line 276, in <module>
Traceback (most recent call last):
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/examples/random_ltd/../../pretrain_gpt.py", line 276, in <module>
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/examples/random_ltd/../../pretrain_gpt.py", line 276, in <module>
Traceback (most recent call last):
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/examples/random_ltd/../../pretrain_gpt.py", line 276, in <module>
iteration = train(forward_step_func,    
pretrain(train_valid_test_datasets_provider, model_provider, forward_step,  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 891, in train
    
pretrain(train_valid_test_datasets_provider, model_provider, forward_step,  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 166, in pretrain
    
pretrain(train_valid_test_datasets_provider, model_provider, forward_step,  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 166, in pretrain
    
pretrain(train_valid_test_datasets_provider, model_provider, forward_step,  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 166, in pretrain
Traceback (most recent call last):

  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 166, in pretrain
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/examples/random_ltd/../../pretrain_gpt.py", line 276, in <module>
    iteration = train(forward_step_func,
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 891, in train
iteration = train(forward_step_func,
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 891, in train
train_step(forward_step_func,
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 502, in train_step
iteration = train(forward_step_func,
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 891, in train
    iteration = train(forward_step_func,
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 891, in train
pretrain(train_valid_test_datasets_provider, model_provider, forward_step,    
pretrain(train_valid_test_datasets_provider, model_provider, forward_step,  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 166, in pretrain

  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 166, in pretrain
    losses_reduced = forward_backward_func(    
train_step(forward_step_func,  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/schedules.py", line 150, in forward_backward_no_pipelining

  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 502, in train_step
    train_step(forward_step_func,
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 502, in train_step
        train_step(forward_step_func,iteration = train(forward_step_func,

  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 891, in train
    iteration = train(forward_step_func,
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 891, in train
train_step(forward_step_func,
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 502, in train_step
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 502, in train_step
    losses_reduced = forward_backward_func(
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/schedules.py", line 150, in forward_backward_no_pipelining
losses_reduced = forward_backward_func(
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/schedules.py", line 150, in forward_backward_no_pipelining
backward_step(optimizer, input_tensor, output_tensor,
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/schedules.py", line 97, in backward_step
    backward_step(optimizer, input_tensor, output_tensor,
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/schedules.py", line 97, in backward_step
model.backward(output_tensor)
    backward_step(optimizer, input_tensor, output_tensor,
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/schedules.py", line 97, in backward_step
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
losses_reduced = forward_backward_func(
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/schedules.py", line 150, in forward_backward_no_pipelining
losses_reduced = forward_backward_func(
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/schedules.py", line 150, in forward_backward_no_pipelining
train_step(forward_step_func,    
train_step(forward_step_func,
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 502, in train_step
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/training.py", line 502, in train_step
    model.backward(output_tensor)
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
    model.backward(output_tensor)
    backward_step(optimizer, input_tensor, output_tensor,
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/schedules.py", line 97, in backward_step
    backward_step(optimizer, input_tensor, output_tensor,
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/schedules.py", line 97, in backward_step
    losses_reduced = forward_backward_func(
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/schedules.py", line 150, in forward_backward_no_pipelining
losses_reduced = forward_backward_func(
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/schedules.py", line 150, in forward_backward_no_pipelining
model.backward(output_tensor)
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
model.backward(output_tensor)
    return func(*args, **kwargs)
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/runtime/engine.py", line 1882, in backward
return func(*args, **kwargs)    
    return func(*args, **kwargs)  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/runtime/engine.py", line 1882, in backward
backward_step(optimizer, input_tensor, output_tensor,    

backward_step(optimizer, input_tensor, output_tensor,      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/runtime/engine.py", line 1882, in backward
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/schedules.py", line 97, in backward_step

return func(*args, **kwargs)  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/Megatron-DeepSpeed-internal-dev/megatron/schedules.py", line 97, in backward_step

  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/runtime/engine.py", line 1882, in backward
    return func(*args, **kwargs)
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/runtime/engine.py", line 1882, in backward
model.backward(output_tensor)
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
model.backward(output_tensor)
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
self.optimizer.backward(loss, retain_graph=retain_graph)
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/runtime/fp16/fused_optimizer.py", line 372, in backward
self.optimizer.backward(loss, retain_graph=retain_graph)
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/runtime/fp16/fused_optimizer.py", line 372, in backward
self.optimizer.backward(loss, retain_graph=retain_graph)    
    self.optimizer.backward(loss, retain_graph=retain_graph)return func(*args, **kwargs)

  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/runtime/fp16/fused_optimizer.py", line 372, in backward
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/runtime/fp16/fused_optimizer.py", line 372, in backward
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/runtime/engine.py", line 1882, in backward
return func(*args, **kwargs)
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/runtime/engine.py", line 1882, in backward
    self.optimizer.backward(loss, retain_graph=retain_graph)
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/runtime/fp16/fused_optimizer.py", line 372, in backward
self.optimizer.backward(loss, retain_graph=retain_graph)
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/runtime/fp16/fused_optimizer.py", line 372, in backward
self.optimizer.backward(loss, retain_graph=retain_graph)
      File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/runtime/fp16/fused_optimizer.py", line 372, in backward
scaled_loss.backward(create_graph=create_graph, retain_graph=retain_graph)    
scaled_loss.backward(create_graph=create_graph, retain_graph=retain_graph)  File "/opt/conda/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
    
scaled_loss.backward(create_graph=create_graph, retain_graph=retain_graph)  File "/opt/conda/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
    
scaled_loss.backward(create_graph=create_graph, retain_graph=retain_graph)
      File "/opt/conda/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
  File "/opt/conda/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
scaled_loss.backward(create_graph=create_graph, retain_graph=retain_graph)    scaled_loss.backward(create_graph=create_graph, retain_graph=retain_graph)

  File "/opt/conda/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
  File "/opt/conda/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
    scaled_loss.backward(create_graph=create_graph, retain_graph=retain_graph)
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/opt/conda/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
      File "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)    
torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)  File "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    
torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
  File "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
      File "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt    KeyboardInterruptKeyboardInterrupt
Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward passKeyboardInterrupt    


Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
    
Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterruptKeyboardInterruptKeyboardInterrupt


Traceback (most recent call last):
  File "/opt/conda/bin/deepspeed", line 6, in <module>
[2022-10-29 01:42:37,683] [INFO] [launch.py:286:sigkill_handler] Killing subprocess 75431
    main()
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/launcher/runner.py", line 519, in main
    result.wait()
  File "/opt/conda/lib/python3.8/subprocess.py", line 1083, in wait
    return self._wait(timeout=timeout)
  File "/opt/conda/lib/python3.8/subprocess.py", line 1808, in _wait
    (pid, sts) = self._try_wait(0)
  File "/opt/conda/lib/python3.8/subprocess.py", line 1766, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
  File "/home/xiaoxiawu/TokenDropping/deepspeed-token-drop/DeepSpeed-internal-connor/deepspeed/launcher/runner.py", line 511, in sigkill_handler
    result_kill = subprocess.Popen(kill_cmd, env=env)
NameError: free variable 'kill_cmd' referenced before assignment in enclosing scope
[2022-10-29 01:42:38,704] [INFO] [launch.py:286:sigkill_handler] Killing subprocess 75432
[2022-10-29 01:42:40,574] [INFO] [launch.py:286:sigkill_handler] Killing subprocess 75433
[2022-10-29 01:42:40,576] [INFO] [launch.py:286:sigkill_handler] Killing subprocess 75435
[2022-10-29 01:42:40,751] [INFO] [launch.py:286:sigkill_handler] Killing subprocess 75437
[2022-10-29 01:42:40,754] [INFO] [launch.py:286:sigkill_handler] Killing subprocess 75439
[2022-10-29 01:42:40,759] [INFO] [launch.py:286:sigkill_handler] Killing subprocess 75441
[2022-10-29 01:42:40,762] [INFO] [launch.py:286:sigkill_handler] Killing subprocess 75443
[2022-10-29 01:42:40,898] [INFO] [launch.py:295:sigkill_handler] Main process received SIGTERM, exiting
